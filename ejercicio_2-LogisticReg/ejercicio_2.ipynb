{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso de gradiente para regresión lineal\n",
    "\n",
    "En el ejercicio anterior aprendiste regresión lineal y encontraste una solución analítica a través de algebra lineal, ahora resolveremos el mismo problema llegando a la solución de manera iterativa. \n",
    "\n",
    "En la práctica, descenso de gradiente se utiliza en problemas en los que obtener una solución analítica no es posible como regresión logística o redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1) (200, 1) (100, 1) (200, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e0b4f10f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrB0lEQVR4nO3de3hU1dk3/u/MkAQISSBQSIKI8YghKqJGQLRCRWIRtNX6egL61NdHEavorxbxUESriO2vokXwUB8frRW0tQqoDWJREUkMiiiYooJRKSSkAiYhQBJm7/ePyZ7MYR/Wntmnmfl+rssLk+zMrDlk9r3Xuu97+WRZlkFERETkEL/bAyAiIqLMwuCDiIiIHMXgg4iIiBzF4IOIiIgcxeCDiIiIHMXgg4iIiBzF4IOIiIgcxeCDiIiIHNXD7QHEkiQJu3btQl5eHnw+n9vDISIiIgGyLKO1tRUlJSXw+/XnNjwXfOzatQtDhgxxexhERESUgB07duCII47QPcZzwUdeXh6A0ODz8/NdHg0RERGJaGlpwZAhQ8LncT2eCz6UpZb8/HwGH0RERClGJGWCCadERETkKNPBx9q1azF58mSUlJTA5/Ph1VdfDf+ss7MTs2fPxkknnYTc3FyUlJRg2rRp2LVrl5VjJiIiohRmOvhoa2vDKaecgkWLFsX97MCBA9i4cSPuvvtubNy4EX//+9/xxRdfYMqUKZYMloiIiFKfT5ZlOeFf9vnwyiuv4OKLL9Y8ZsOGDaioqMA333yDI4880vA2W1paUFBQgObmZuZ8EBERpQgz52/bE06bm5vh8/nQt29f1Z+3t7ejvb09/HVLS4vdQyIiIiIX2ZpweujQIdx+++248sorNaOg+fPno6CgIPwfe3wQERGlN9uCj87OTlx++eWQJAmLFy/WPG7OnDlobm4O/7djxw67hkREREQeYMuyS2dnJy677DLU19djzZo1ums/OTk5yMnJsWMYRERE5EGWBx9K4PHll1/i7bffRv/+/a2+CyIiIndJQeCb9cD+3UCfQcDQMYA/4PaoUobp4GP//v3Ytm1b+Ov6+nps2rQJhYWFKCkpwaWXXoqNGzfitddeQzAYRGNjIwCgsLAQ2dnZ1o2ciIjIDXUrgKrZQEtED6v8EqByAVDG1hIiTJfavvPOOxg3blzc96dPn4577rkHpaWlqr/39ttv49xzzzW8fZbaEhGRZ9WtAF6aBiD21NnVUvyy5zI2ALG11Pbcc8+FXrySRNsQIiIi75KCoRmPuMADXd/zAVW3A8MmcQnGAPd2ISIiEvHN+uilljgy0LIzdBzpYvBBREQkYv9ua4/LYAw+iIiIRPQZZO1xGYzBBxERkYihY0JVLUpyaRwfkD84dBzpYvBBREQkwh8IldMCiA9Aur6ufJDJpgIYfBAREYkqmxIqp80vjv5+fklGl9maZfuutkRERGmlbEqonJYdThPG4IOIiMgsfwAoPdvtUaQsLrsQERGRozjzQUTkBdyojDIIgw8iIrdxozLKMFx2ISJyk7JRWWzb7paG0PfrVrgzLiIbMfggInKL4UZlCG1UJgWdHBWR7Rh8EBG5hRuVUYZi8EFE5BZuVEYZisEHEZFbuFEZZSgGH0REbuFGZZShGHwQEbmFG5VRhmLwQUTkJm5UltGCkozq7XuwfNNOVG/fg6CkVvmUfthkjIjIbdyoLCNVbWnAvJV1aGg+FP5ecUFPzJ1chsryYp3fTH0+WZY9FWa1tLSgoKAAzc3NyM/Pd3s4RERElqva0oAZz2+M6/CiLL4tuXpkygUgZs7fXHYhIiJyUFCSMW9lnV5rOcxbWZfWSzAMPoiIiBxUW783aqkllgygofkQauv3OjcohzH4ICIiclBTq3bgkchxqYjBBxERkYMG5vW09LhUxOCDiIjIQRWlhSgu6KnXWg7FBT1RUVro5LAcxeCDiIjIQQG/D3MnlwHQbC2HuZPLEPBrhSepj8EHERGRwyrLi7Hk6pEoKoheWikq6JmSZbZmsckYERGRCyrLizGhrAi19XvR1HoIA/NCSy3pPOOhYPBBRETkkoDfh9HH9Hd7GI7jsgsRERE5isEHEREROYrBBxERETmKwQcRERE5isEHEREROYrBBxERETmKwQcRERE5in0+iCilBSU5I5s0EaUyBh9ElLKqtjRg3so6NDR3bz1eXNATcyeXpX17aqJUxmUXIkpJVVsaMOP5jVGBBwA0Nh/CjOc3ompLg0sjIyIjDD6IKOUEJRnzVtZBVvmZ8r15K+sQlNSOICK3MfggopRTW783bsYjkgygofkQauv3OjcoIhJmOvhYu3YtJk+ejJKSEvh8Prz66qtRP5dlGffccw9KSkrQq1cvnHvuufjss8+sGi8REZpatQOPRI4jImeZDj7a2tpwyimnYNGiRao/f+ihh/CHP/wBixYtwoYNG1BUVIQJEyagtbU16cESEQHAwLyelh5HRM4yXe1ywQUX4IILLlD9mSzLWLhwIe6880789Kc/BQA8++yzGDRoEF544QVcd911yY2WiAhARWkhigt6orH5kGrehw9AUUGo7JaIvMfSnI/6+no0Njbi/PPPD38vJycHP/zhD7F+/XrV32lvb0dLS0vUf0REegJ+H+ZOLgMQCjQiKV/PnVzGfh9EHmVp8NHY2AgAGDRoUNT3Bw0aFP5ZrPnz56OgoCD835AhQ6wcEhGlqcryYiy5eiSKCqKXVooKemLJ1SPZ54PIw2xpMubzRV9tyLIc9z3FnDlzcOutt4a/bmlpYQBCREIqy4sxoayIHU6JUoylwUdRURGA0AxIcXH3VUdTU1PcbIgiJycHOTk5Vg6DiDJIwO/D6GP6uz0M8hi23fc2S4OP0tJSFBUVYfXq1Tj11FMBAB0dHXj33XexYMECK++KiIhIFdvue5/p4GP//v3Ytm1b+Ov6+nps2rQJhYWFOPLIIzFr1iw88MADOO6443DcccfhgQceQO/evXHllVdaOnAiIqJYStv92Coope0+84G8wXTw8eGHH2LcuHHhr5V8jenTp+N///d/8etf/xoHDx7EDTfcgH379uHMM8/Em2++iby8POtGTUREFMOo7b4Pobb7E8qKuATjMp8sy57a/KClpQUFBQVobm5Gfn6+28MhIqIUUb19D654qsbwuKXXjnItTyidc1HMnL9tqXYhIiJymtfb7jMXpRs3liMiorTg5bb7Si5K7IaISi5K1ZYGx8fkJgYfRESUFpS2+1qLGD6EZhqcbrtvlIsChHJRgpKnsiBsxeCDiIjSglfb7tfW742b8YgkA2hoPoTa+r3ODcplDD6IiGwUlGRUb9+D5Zt2onr7Hv2rWykI1L8HbP5b6F8p6NxA04QX2+57PRfFDUw4JSKyiakEw7oVQNVsoGVX9/fyS4DKBUDZFIdGnB681nbfy7kobuHMBxGRDUwlGNatAF6aFh14AEBLQ+j7dSscGHF6UdruXzRiMEYf09/Vclav5qK4icEHEZHFTCUYSsHQjIfe0VW3cwkmhXk1F8VNDD6IiCxmKsHwm/XxMx6xR7fsDB1HKcuLuShuYs4HEZHFTCUYBnaL3eh+wePIs7yWi+ImBh9ERBYzlWDoHyR2o30EjyNPU3JRMh2XXYiILGYqwXDomFBVi97R+YNDxxGlCQYfREQWM5Vg6A+Eymn1jq58MHQcUZpg8EFEZAOhBEOlqViwAzh3DpAfk3SYXwJc9hz7fFDaYc4HEZFNdBMM1ZqK5RUD594B9D8mlOMxdAxnPCgtMfggIrKRaoKh0lQstrdHayPwzvzQbEfp2Y6NkchpXHYhInXcZ8QebCpGxJkPIlLBfUbsY6apGGc/KE1x5oOIojm5z0gmzq4INguTWhttHgiRezjzQUTdDJcEfKElgWGTkk+E9OLsihQMzTjs321fwqdgs7AbV+7CFH9DxrXdpszAmQ8i6ubUPiMOzK4EJRnV2/dg+aadqN6+J7SJm9GYFpYDz14IvHxN6N+F5dbvKGvQVEySgV1yf6xqPTp+91uiNMGZDyLqJrp/SDL7jDgwu1K1pQHzVtZFbe5WXNATcyeXqc8kaFWfKMGQlb02lKZiL02DDB98EfepxEfzOqciCD98CO1+O6GsKCP3/6D0xZkPIuomun9IMvuM2Dy7UrWlATOe3xi3q2xj8yH1mQQ3qk/KpgCXPYeO3tHPYyP6Y0bnLKySKsL3Ht79NoLpWR0ij+HMBxF1U5YEWhqgfjL2hX6ezD4jJmZXgpJsagfQoCRj3so6vTmV+JkEt6pPyqagqn0Elv71RQzE92hCX9RKwyCpXBNG7pJrelaHyIMYfBBRt4glgdCpOvI0nvg+I5FBxLFtvTBc4Hdq/9MDNy9YY+okW1u/N27GI1LkTEK48ZcTS00aBubnokYqMz6ua5dcZVYnNrhSZnXCbduJPI7LLkQUrWtJwKp9Rqq2NGDsgjW44qka3LxsEyavlLAb/SHr7OJ6sFcRrngzIL500iVyhkBP1HFOLDVpMLP7rdGsDhCa1eESDKUCznwQUbyyKaGEzyTLTtWu1CX4MbdjKhZnLQR80QmX6PpqXuc0BFWujTSXTrooMwRGoo5zYqlJg7L77YznN2rNM4V3v63evsdwVmd38wFsrX4Dw/MPcm8Y8jTOfBCROn8glONw0qVA6dkIwm8qyVHvSr1KqsANnbPQhMLoH+SX4IsfPoZl+0do3q5WEiZgbiYh6nG6uKW90O63MJ7VmeivxbqcmzB89ZX2lgoTWYAzH0RkKJEkR6P8iyqpAm8eOh0rJ/ujrtS3ftoIYJPhmNROxmZmEqIoS02qTc8etL3pme7ut130ZnUm+muxJGth/A/sKBUmsgCDDyLSlWiSo0j+hQQ/tuWOwPCTBoe/l9DSSQRlJiE2WCoyqgixaKkpUaq730ZQZnUamw9FvRZ+SJib9Vzo/+OmfCzuSktkEQYfRKQpodLVLokGEVonWYUPoUAiaukkhshMgiplqcmDtGZ1KvxbUeKLX4Lqxo3qyHuY80FEmsyUrsZKKP8C3SdZ5ZjY3wE0lk5iKDMJF40YjNHH9E+LDqFq+SED8b3YL9tQKkyUKAYfRKQpodLVLskEEaJJmJmosrwY62aPx9JrR+GRy0fgukmCVTg2lAoTJYrLLhnMbPdISl6qPeeu5V8giaWTDBCVHyIVAR+4UyqcSVLtb9frGHxkKLZodl4qPucVpYXo2zsL3x/oVP25rfkXME7CJNjWlZa6peLfrtdx2SUDmd54i5KWqs/56rpGzcADCJ3mMjX/wlMs7kpL3VL1b9frOPORYZKpXqDEpOpzroxbT7/eWZhQVuTQiEiXy6XC6ShV/3ZTAWc+Mkwy1QuUmFR9zo3GDQD7DnQajpvbvzsopistA4/kpOrfbirgzEeGSaZ6gRKTqs+5FePmWjmlslT9200FnPnIMMlWL5B5qfqcJzturpVTqkvVv91UwOAjwyTa+IkSl6rPeTLj5vbvlA5S9W83FTD4yDBWdY8kcan6nCczbq6VUzpI1b/dVGB58HH48GHcddddKC0tRa9evXD00Ufj3nvvhSRJVt8VJYjdI52Xqs95ouPmWjmli1T92/U6yxNOFyxYgMcffxzPPvsshg8fjg8//BD/9V//hYKCAtx8881W3x0liN0jnZeqz3ki487ItXIp6FiZK7ttOitV/3a9zPLgo7q6GhdddBEmTZoEADjqqKOwdOlSfPjhh1bfFSWJ3SOd59Xn3OhkZnbcVuxMm1LqVgBVs4GWXd3fyy8JdR61uMEXK4jc4dW/3VRl+bLL2LFj8c9//hNffPEFAOCTTz7BunXr8OMf/9jquyIiC1RtacDYBWtwxVM1uHnZJlzxVA3GLliTVDWK2bXylO4FUrci1No8MvAAQnutvDQt9HOLsIKI0oVPlmVL/8plWcYdd9yBBQsWIBAIIBgM4v7778ecOXNUj29vb0d7e3v465aWFgwZMgTNzc3Iz8+3cmhEFEM5mcV+CCgBQrJr2iJX6XrHeH6qWwoCC8vjA48wH+T8EtRMfgdNbZ1JPYagJGPsgjWaibzKbNK62eO99RxRxmhpaUFBQYHQ+dvyZZcXX3wRzz//PF544QUMHz4cmzZtwqxZs1BSUoLp06fHHT9//nzMmzfP6mEQkQEnWkcbrZVrBT+NzYdw/fMb4za189zywjfrdQIPAJDha9mJR555FjVSaCYo0cdgpoKIywPkdZYvu9x22224/fbbcfnll+Okk07C1KlTccstt2D+/Pmqx8+ZMwfNzc3h/3bs2GH1kIhIhVPlsFqbyon0Aond1M5zywv7dwsdNhDfh/8/0cfACqLEpPSSXhqzfObjwIED8PujY5pAIKBZapuTk4OcnByrh0GUEtyqWghKMt7f9h+hY+06mYnsHRPLls28kqlS6T1A6LD/oHsKOtHHkJEVRElicq53WR58TJ48Gffffz+OPPJIDB8+HB9//DH+8Ic/4Be/+IXVd0WU0tz6YFS7Xz12ncwSDWosXV5ItkrFl1jwk8hjyLgKoiTpLenNeH4je3S4zPJllz/+8Y+49NJLccMNN+DEE0/Er371K1x33XW47777rL4ropTlVtWC1v2qsbt1dLJBTdIzMlZUqbSJzR79AC2q3zfzGJLqtikFgfr3gM1/C/0rBYXvNxWxvb/3WT7zkZeXh4ULF2LhwoVW3zRRWnAi0dPs/cYKn8wuPAGBb9bZ0jhrX1tHUr+fVPAiBUMzHnqvQtXtwLBJ+o+3zyChu2tCX9Xvm30MSrfN2JmrIr0ZMwd7kHgFk3O9z/Lgg4j0ufXBaCbHoqigJxaP/DdOXT3BlpNWUJJx3+t1Cf2uJcsLAlUqaNkZOq70bO3cnKFjQs9JSwPUAhlJBhrRH7XSMMseg6lum8rsTuzYlNmdy55LywCEybnex+CDyGFufTCK3t6N447FLUdsReCvN8Ouk1YiyaaAhZt5CVapYP9u49ycygVdJ3gfIp8vuevrezunQopY4bbiMQh127RqdicFMTnX+7irLZHD3PpgFL29s47uh8Cq26F90kLopGWQN6BX4igaCPXtlRX1tWWbeQkul9T+p4dxbk7ZlFAwlh89Jl9+CT4Z8yg+yTvHnsdgxMzsTppRknO1Qju785nIGGc+iBzmVtWC8P0GtppaklBjNFsgGgg9dtVI+H0+60uRDZZLlM6kt9T0hoxQrxE/JFT4t2IgvkcT+mKDNKw7N6dsSmgGIaZk91R/AOsmuLQJnInZnXSjJOfOeH5jzHyUhbNnlBQGH0QOc+uDUfh+294Xu0GNk5ZIieOEsiKhQGjU0f3tOUH4A5rLJcqzsfWUO7FzdSjwmOivxdys51Di6264tksuxLzWaaitHxFaAvEHVIMx1zYkE5zdET4uxSSUnEuO4bILkQuUD8aigugZgKKCnph13vFoPyzZ0o1R737DSwFJnLRESxwBJF42ahWN5RLkl+Dj0Y/ginU/ABAKPJZkLUQRoju9FmEvlmQtRODzlfaNMRnK7I7e4kP+4NBxaaqyvBjrZo/H0mtH4ZHLR2DptaOwbvZ4Bh4eYPnGcskyszENUaqLrKL4+rs2LK39Fo0t3Rst2tV0TLezanizNO0lCeSXALM2xyUqVm/fgyueqjG8/6XXjsLoY/p7owNlTIfTqv2lmPGXTyAjtNSyLucmFGEvVNtnyEBnbjFyfvWZN5M2w9UugOpcV5pWu5A7XN1YjojEKVPyVVsasPCtL4W6MVrRkl13KUBgSQKVD6qebM1W8pgqG7VLxHJJUJIxb8Ga8COu8G+NWmqJ+1UfkHOgQTf/xVXK7I5qn48HGXiQaxh8ELnMTNOx1XWNzswUlE1B8GfP4vDrv0bOgcbu7xuctBKp5HEtJ0JFbAlw5IZwuryctKmRDOvJmRrKGAw+iFwm2nRs0ZptWPjWF47sVRFaDumD3c2/D1d4HM4diCkTLkFl2RGav5fq+4/EztxodSaN4/WkTY1kWCK3MOGUyGWiSxVPrt3uyF4Vkfu/SPCjRirDCmkM3mg9Ftf/5RM88taXmvcjtP+I0rLdjn1GktzDJHbmplYahl1yIbSf1vRP2iSyA4MPIpeJLlW0dWifSCNbsidDZP+Xh9/6Amc9+E/Nze/0Kmr+Pu47VK6eADx7IfDyNaF/F5aLbeJmpG5F6LaSuO3Y5lQS/JjXGUrYjA9A9PNfiEgbgw8ilxl1YzQj2Zbsom3PG1vadXffVS1xnLIfp1bfnNwuslqs2KEW6jM3q6QKzOichUbELBXll7BahChBDD6IXKa3VGGW09vU6y31KImkF40YjNGlfXVbtssAZIGW7aoM9zCBUDt4hdrMzSqpAj/LeQK15zwLXPI0MP21UKlxZOCRYdvWEyWDCadEHqDVjVGUVYmcZoIXU7vvGuwz4utq2V77zkpUjL9YeAwity3SDl6hlDG3H5bw+5+dAsjAd23txiXAHty23oqSbCK7MPgg8ojYnhdf7t6PRW9vE/59KzqCGlWrqBGaLREsRX3+rQ3YO/BMc1U7Fu1hotfwTDe48uC29Z5o3kakg8suRB4SuVRx1rEDhH6nMDfLsjLbyCUgUUKzJYKlqE3oa75qx4I9TCIrfCJF7V6rxuIlHysk/FiIHMTgg8ijRBJR++dmo2bOeZZezYZzHvL1gwpT25If2AP4tD9uJBnYJfdHrTTMfNVOknuYiO5HoxoQeWzb+qQeS4L3V719D5Zv2mnLXkSUvrjsQuRRIrvQ3v+TcmT3sP4aQlkCWrTmSzz81pdxPze1+VvdCuCvP4f67EB3Ceu8zqmQuq6HTCW+JtEOHhBv8qaa2+Kxbeu1HosfUrhZXFNrX9RuPwmjjxuY1H1xaYeSwZkPIg8T2oXWJgG/Dzefdzwev3okihO9f91lia5D4McNnTdhlVQR/p7pqh2dHWqNci7M7kcTxWPb1quNcaK/FutybsKy7N/i0exFWJb9W4x4eWxSpc1c2qFkceaDyOPMbr5mdZVDUpu/GS5LAD18Er5HaAfMpKp2EtzDJJH9aMKUJR+jHYAd6oAaO8aJ/losyVoYd1zPQ00JJ8Oa2Ysomfcdq3XSG4MPohQguvmaJVPhMVvMY+gYBPyBxDZ/E1xuGIjvzS3laElgD5Ok9qNJcsnHapGPxQcJc7OeCw0z5un0KWFC1e2hgM3E+JJaphLEJZ30x2UXojRhyVS4BS3Ko5iocnFiKUmN0H40egFREks+Vot8LBX+rSjx7Y0LPLollgyb1DKVAC7pZAbOfBClAUumwi3sVxGeMm8ZisreRcg+sLvrajt2bD4c7DUIN181HRXH/MC1aXWtJm9FolfbHtq2Xnks61/dABwW+AWTybBJLVMZcGpJh9zH4IMoDSQ9FW7Yr0J8ij52ynyi/3I8nr0QMnwxAYgPPgC9J/9Ov/JCZRnIjpN6UrktgKe2ra8sL8aE3uOB5x42PthkMmxSy1QGnFjSIW9g8EGUBpKeCreoRbkyZR55UlolVWBGxyz8Jus5lPgi+nfkl4TyIfRmUxxuWy6aW5MKAkedZUsyrEgJeKJ5O3Yv6ZB3MOeDKA0kPRVuQb8KvSnzKqkCZ7c/ihuy7oX00z+pb8wWy6Kdal3n1oZzSjIsAM1slgSTYe0qAbdzSYe8hTMfRCnAqOww6alwC/pVGE2ZB+HHG63H4oPcURhdajC7YOEykKvc3nBOSYZVHYPBrJOBpJepVNi5pEPewuCDSItDuQZGRMoOk54Kt6BfhaVT5hbuVOsar2w4Z2MyrNXLVHYu6ZC3MPggUuPyFasy07G6rhH/8/7XcT9Xyg4jp7iTqtiwoF+FpVPmHmtbrkV5nRpbDmHv/nYU5majqKAXKoYWIOClmRsPJcMaSbryiFICgw+iWC5fsarNdMTSKjtMaio8ySl6S6fMvdK2XGf2S+91+nHeNizuTPGZGxfZsaRD3sLggyiSy7kGatUiWrTKDpOaCjeYotfLPbF0ytwLbcvrVgD/+DXQGtHUKq8YuOAhVEln6L5OPdqagGyB+3B55saImy3O06nyiOIx+CCK5GKugV61iB7Lyw41puhFck8smzJ3u2153Qrgpanx329tgPzSVLzT49eQMULz15vQV+x+HNpwLhGp2OKc+8GkDgYfRJFczDUwqhbR4kTZodaMjFbuiSVT5hrLQHJ+Cb449U5s7TgNA7fvsf4EIwWBlTfpHvLrzsV4CY9D0uhWUCsNwy65EEXQam/u7IZzZpl5vb0iFYOlTMbggyiSi7kGZmcwEik7TOTKMJGW15ZNmccsA9X+pwduqemNnas6AWwCYMMJpv494OA+zR/7ABT69uNMfx2qpXLVYyT4Ma9zGpZkqXd2BSA0c+PGlXwqtjhPxWAp0zH4IIrkYq6BmRmMRMoOE70ydL3lddcyUNWWBsx4cyNkdEb92PITzDfrhA4b7atDNdSDD6Crs2vnLDzadxlyDjR2/0AwgdetK3nXX2+TUjFYInY4pQwSlGRUb9+D5Zt2onr7HgQllY+rBLtCCt22AaVaROTj0WwnyWR2CvVCy2ujEwwQOsEk8rxr3qARgRfq07xz0OPWz0IdXS95WqyzK6zb2TWR96UXXm8zzARL5B2c+aCMYOoq0mTJqVVXqHrVIoprzjoK55UVmZp+T/bK0NaW14KN3By9Gi89G3jvd4aH1Uhluj/3oWtmqkcPU8nJVl3JJ/q+TLUW56kWLFEIgw9KewmtBwt2hbR6rVmrWiSZ6fZkT9y2tbw20chN7cThh4QK/1YMxPdoQl/USsOsOcEcNRboVQgc1LlS7lWIaZdchfrXPld9bk2/XhFB2NaWXtjdLEFrYlok0ErmfWn0egNA/9xsnDa0n9BDs1uqBUsUwuCD0lpSV5EGXSHtWmu2usFSsleGtrS8NtnILfbEMdFfi7kxu+TukgvRuu+3AK4SH4cafwCY/Ih6qa3izOtRObwYE4YPVu9waub1ignChgNYl1OIeZ3TsEqq0Pw1rdcr2felyAzcnrYO/PB3b7tTSRIzW1YxdDT3g0lBzPmgtGbnerCdt61Ui1w0YjBGH9M/qUQ5K64MLd3F1LCRG0KN3CJ2f1WuxoFQ4LEkayGKEP28FmEvjn93pjW73ZZNAS77c2gmRs07DwALyxHYuhKjj+mPn5w6GNecfTR+MvIIc69X3QrIL02DHNNbpgh7sSRrISb6azV/Vev1suJ9qfV6RzKbf2KJuhXAwnLg2QuBl68Bnr0QgUdPwuKR/wagmaXF/WA8iMEHpTU714MdW2tOckt2o0RWH0LLBEZXhpXlxVg3ezyWXjsKj1w+AkuvHYV1s8ebv/I108itS8Dvw92TToQfEuZmPQcAcf0z/D5Ahgw5JnBJWNkUYNYW4Nw71H+uzNIkGuxIQRxceRtkyHGvjfLY5mb9GX5IUT8zer2sel9Wlhfj3dvGoTA3S/Xnlif6GlFmy2LfOy0NOLX6Zvx93HfWBMfkCC67UFqzcz3YkbVmCza4s3LZxJL+HQk2cuuXm4MK/9aopZZYfsDaDrRSEKh9UuOHybXbr31nJSoONmr+3O8DSrAHFf6t4eRWkdfLyvflR9/sw962Ts2fO1Z2K7DtwamfLcC62z5F7TfN7HCaAmyZ+di5cyeuvvpq9O/fH71798aIESPw0Ucf2XFXRLqsuup3+rYB6F7pmb3itnTZJFkJNnJraj2Egfhe7Het6EBbtwL4wzDgwHc6B8XP0ogISjJeW79J6NjIxyzyeln5vvRMJYngbFlgR7Vly5VkL8tnPvbt24ezzjoL48aNwz/+8Q8MHDgQ27dvR9++fa2+KyJDtiRLOnDbiW5wp9cR0zM7hSbYyG1gXk/hPVPWNQYQ6J1E63WthFgtJoOd2vq9+OJArtDmc9dNGoMf5Y4Qfr2sfF96ppLExW0PyB6WBx8LFizAkCFD8Mwzz4S/d9RRR1l9N0TCLNvszMnbTmCDO5G+Dp7YKdQfQHDig/D/dTog0nq8q7rhzLZGDOjdA7s6+6EI+1T3TJFkoBH9Me2fPSD9syaxEmXdwE+DyXb7Ta2HDPd/kWTgUO8iDB9dieEml3Ssel/aVmZtlovbHliBG97F88mybGmmUFlZGSZOnIh///vfePfddzF48GDccMMNuPbaa1WPb29vR3t7e/jrlpYWDBkyBM3NzcjPz7dyaJTh7PwAsPy2N/8tlM1v5JKngZMu1ezroIzAS0l3b3y6C3ct34IzDr4fVy6L/MHRjdxUcl72yn3QF/sBRCedKjmPMzpnhUtUE3r89e+FqimEdM3SzNpsKuejevseXPFUTbhyB1B/LF+euxgnjAuVDie6L0+y70vlvQWoz6I48t6SgqEqF6PZMpOvgxMyacO7lpYWFBQUCJ2/LQ8+evYMTb/deuut+NnPfoba2lrMmjULTzzxBKZNmxZ3/D333IN58+bFfZ/BB2U00RPg9NcQHDoWYxes0SyvVK5O180en3BAZFVwNf+NOjyxtj78dWyjsJ9fcQUqTzoi9EONpQ9JDj2mfeiDQt/+8Pd3yf0xr3NqXG8M049fNPBTbj2mJ4mIoCRj7II1aGw+hPNVe5b0x6NZ1+D+O+5AwO8zfwIT7BwryhMn0PD7AVANgxJ4HeyWShcFVnA1+MjOzsbpp5+O9eu7E7BuuukmbNiwAdXV1XHHc+aDSIWJK73q+u9xxVM1hje59NpR4ksuESev8E6yLd1VD4mceN74tAE3vLBR95hiJUiA1PX41ZeeQssrhfj/Oq/HD9AS7nCqtcU9YOLxiwZ+vQcAFz5s/oTX9dx+8q+tmL/ue2yQhkEGooKwDdIwPHb16agsLxY+gSkBYuDzlThly3yVzezEK6TUeGLpQLX6a7DQRn1OUwJMOy8KvMZM8GF5zkdxcTHKyqL3PDjxxBPx8ssvqx6fk5ODnJwcq4dBlDLUP9S7Nrh7aRqglTbYlRdheUVCzAd8BYC/yoWY5+/uuGm2fXxQknHX8i2Gx4XLNv11ujkvoTLUvZDhxwpJbIdh4cdvmBCLUOBx67+AHgIZo5EinttTACzLBnajP37T0T1jU1zQE491BXai3UolCbjv9Tqc3Lo2vIwTVe6i0Tk2ll6A4Yl8IcFtD/Q4FUSl2u7ATrM8+DjrrLPw+eefR33viy++wNChQ62+KyJ7WTx1rUZ/OltsgztLKxI0ljqUjptKPoXZ9vG19Xuxt61DaJxNrYeAgFjVgnDpLUxUZIgEfhc+nFjgofLcDsRePJ79CDZULETwhMlRJ0PRE9gNL2wMNWDLUW/AJtKTxBNLKyIMtj3Q4+Rj9EyZskdZ3ufjlltuQU1NDR544AFs27YNL7zwAp588knMnDnT6rsiso9KG2csLLemdXcXoW3TlS6bOluyW9bXQafKQ63jppn28WY+YAfm9RSuWhApvU2o34qys3F+zAkpv8Q4t0CtI+3hDuC1WVB7bn1dHU4rtj6E0aV9owI5M8+b0oBNOw7U7kki9F5McU4/Rs+UKXuU5TMfZ5xxBl555RXMmTMH9957L0pLS7Fw4UJcdVWSmz1RenFgViFhJjc9S4S5zb9CV3rh6eJPG6Omiy3r62BQ3qvWcRMQO0FGfsCq7Uar5GoU5mZ1BQn6Sx9KzketNEz3fpPqt5LIFL9aTkKvfoB0GGhv1bmz+NJpwNyJKdEGbHZtkOglbjxGz5Qpe5Qt7dUvvPBCXHihaKkaZRyBluGuJbcl2NzLLLPrwUbTxZb0dRBs0BR7khM5QSofxCe3rlXdjVbZwfW3F5V3vc56Sx+hQKin3IEJ/g+jqlv69s7C9we6E2OT7rdiZopfK2g9uE/47qTWxqjpaJHt7RWiDdhiZ5UyITfBjcdoaxPCNMC9XchZArMKVdIZ7q09Czb3Cn79PgJHn5Pw3ZhZD9aqdohN+ky6g6nJpQ4zV24Bvw+LR/4bp6xfGPczJZ/klePm48cnT+r+QdfSh7zyZvgOxi/t9MX+cB7KarkCi64YiYnlLnVwTaQxmYobV+7CFH9DVFM4vRNY5NdGTctk+OBT6RybCbkJbj1GOxscpjruakvOEdhK/eDK2zDz+Q/dW3sWvPqf98KapMYiOp0+IDdHd7oYiN5VVKlIUN3bwmh3XKXKQyN7RJJD/SdqpWGaV25BSUb19j1Yvmknqrfv6d7tVAri1M8ehM+nvhutz+fDJbv/CHz1bvT4hk1CB7LCTbdifw8I5aFAltAvN1v/8dvJMGjVpzy3q1qPjnuf6+3Ls/jKU8P5PhL8mNc5LXx7sbcPyPh4+Oy4GbtMyE1w8zFatht0muHMBzlHYFah18FGnBGTUxD6iUNrz4JX/18cyMWfTZSaxhJdD4YP1kwXi+yOq1PloWzqPq9zKiT4VWeidJeGcrcBLbt0kmJloHUX8FxELk1+CTDy58g5uFsrHorKQ2lqHan9+O2WxJ4iSqAwr3MqgvCrvs+VWa2a7XtQ/dV3AEJB1qij+8Pv94VnRlZJFZjROSu0tIXu2aJG9Me9HVOx6u0BWDK4Iep1y4TcBLcfoyfKlD2GMx/knARzChRmqisSZuLqH4iedTBDmU6Hyj1Fzip8t78dInSni83sjqtR5eHLH4wvz12MH1/236pXbkaVBJ/8a6vQ44gb3zsPCB06EN+7e2WexJ4ie5Ef1RJe632+uq4Rv/rbJ1j09nYsensbrvrTBxi7YA0ARM2MrJIqMLb9UVzecRdu6rgRl3fchbHtj6Cq6/Zj37Oi78VUzk3IhMeYahh8kHMsKp+0de1ZufoHugogu0VeoUrwJx0MiWxzn/R0scFSlwzgwMrbUP1lU/cJSaW81zdrM04Yd5XqcoZRJQEAPPHxAaHHof7bxg7nDnT3ytwgaFUjy8B3cj5GtS+KawkPRL/Pq7Y0YObzH2Jo60ZM8a/HKH8d/JDCwR0ArJs9HndPOhFAaAmmRirDCmkMaqSycDWR1ntW5L2Y6jLhMYrQXBp1GJddyDkGnSNl+NAgG5dP2n6F23X1f2jFr9DrUPdsTSPU9w5JJhgyShJNerrYYKnLBxm9DzbikWeexTd5I7uXUkxUeYhUElS1Ho32wiLkHNiNRJIylWW3WMoutlOmXOLuVatuY7J4yuf9nZ2/wGGNj2HlfR6UZLzz6v/gvZw/qVYJvSlVhJdpBuSJdYtWe88mnbCcAjLhMerxUiM5znyQcyJmFbQmPx/NugayxtsyoWZRJkRdEeSchY0/fS9u6lrtCjXZYEgvSVJvuhgIneJ+3FXhoXoFY2KpK9GkXpHgS4Ifn5TP6foqsQ/62EcnyYDPB+weM7d7M7oEWHYlqNWYrFdh6L8ITb7+uCFiqSVS7Pt827sv4IHOh1CE6NkKpUrofH9teDYj2Zky1xJ2HZQJj1GN1xrJceaDnKV8QKskP/oqH8S50hl40YW6eLUrgqL8HBzqeQo+ONDpaiKeVrme3xc6AT/9/td4+v2v1a9gTCx1mU3qVXqxfLl7v+5x4eNPmAwcVRj/2gt4uPMSXN7j7agr/87cYvSYtACnDr/I1G1FsvxKUKsxGRD1vU37S7HqL58Yv8+lII78ILTrt1qVkCSHqn1Wt5+OptZDuPDkkrRPHiXzvNhIzvJdbZNlZlc8SmE6HU6dnhrU2zVUVvl/5WtAZ0tsGzq4Kif71XWN+J/3v477ueqYDHbHVZYtxrY/ErUjrNEOsGqvkZ7wbrVdJ1R8sx6ofxdY+zvD3/1OzkdF+2L4AEzM+wqLJpfAn1dkyTbxbm53LvQ+F9xh9/KOu3DzNb8IN6RT8kBMvWcpbVVv32P9ztcqXN3VlkiITk6Bk+uyIlcEBb2z0LNHAI0tgk2CRMpaExDw+1BRWohbX9qk+nPVKxi98tmYBNpIekspWidtPXdPOrH79et67WO7eWrpie5Opm+0HosPckdhdGlyZYt6r7uvq/37+lc3YELv8QgcdVZ3kGNhUCn0PhdcNjuhVysqfJ8Bm5tQ2WcQllx1Cua99rljja1c60hMQrzYSI7BB3mSU3XxIsmS3x/oxF+uGQm/32f84WrzvjAJtYnWWOrSSqAFtHMC9E7aevrlRidCVm1pwIqVu7BY4Hd741DUjrpWfEBqPY8T/bXd7d8PA3ju4e7AEbA8qDR8nwsum90ReA6B5x4Jf12ZX4IJUx5Ebc+xtgcEXkpiJHVebCTH4IMymuiJ7Lu2dlw0YrD+QYZlraF9YXxJ7AuT8BVMVy5C8Ov3Me+FNfjiQG7Uhm4Ko5wAo+BHZDzKzIkPR2NXjnY7cEVsboOpD0iNmQq153GivxZLshbG30ZLA/DSVPXbt3CzQVUGFWISQq9ZTkfM/jEtDQj8dTpGX/YcMMKGcXURbf1P7nK7yZoaVrtQRrP0ikCgrNXXshO176wUHV5i49A6zh9A4OhzMObi6/CBVBZXVSSS1JvorENk2agyc6LXDjxu6D6gxLcHlXlfiX9A1q0I5bs8eyHw8jWhfxeWA3Ur4p4fPyTMzXoufF/R9AbX9bOq2+Pb1VtBp0JMWWZTf6WsGZdeJZBIf5dEm/C5wSv9L+zgxSZrDD4ooylXBHp/cn17Z0GSZM0PI+VD68PP/iV0n8+/tSHhsjaj8YqUIyfTbMnstGzseGJnTpR24M3IFbq9607tLfYBadDVteLQuqjnscK/FSU+/RkYbaHNBvHN+kR+2ZhW19neAwyKlpMbV9WWBoxdsAZXPFWDm5dtwhVP1WDsgu49jcwsAXqd0WNNB15rssZlF8poeruGKr4/0Imrnv7AcD+TUf5mLMs2vs8m9E24rM2qbboTTeo1s8W72njUZk5WSRVo6eyNpdnGrdRPOVG/AR0AgQ0MfQismoO5F76JGV3lrlot/U1JYn8XQ2olvK0NwN+vtWVcIssp7Ycl1d+N5fXdcDNp6chLTdY480EZT+uKIFZsM57Ypj3KluZas7WR+8LY3ZZdRCLNloyanhmNR2vm5AOpTPe5k+ED8gfHbQevSmADQ7TsRGWf+vDzaNTSX0gS+7sIUSrETro09G+e4AnR5LhEl1MG9BHrpio0W2a047JN0m3pSIRXmqxx5oMIEbuGfrUHM/+yEd8f7Iw7JrKUdfywQXEfWkoOw5KshZDk6NwBtbLWxuaDqN6+R/0KRCVRMgh/1BXLu7eNw0ff7HPsCkYpp2w/LGHWecfjmfX1+P5A/POkuHvSiXGBkNbMSdRzh9irIl8o0Kl8UCxRV/RKf/9uVJ50duhKcPtJOPjyU+h5qCm0w65ZvQeEZiLq37Okp4sQg2RUwBf6uUjAFkF0OQUyrElitKk0XURC1WNkCQYf5FlO9w4I+H3w+3yqgYdC+TD6c/XXqh9aeluax5a13vf6v7C3rSP8dXhZx78h7sP4YK8izOuchmX7R8Qdb1iFYwG1ckq9V8KH0OObWF6s2i5ebdnoTakCN3TOwsMFy9DrYGP3D/JLQoGH6IlI9Eq/67iA34fRxw0EpvxeY28WvXZzXQ58170E4tCJU38/ma7nXDRgi2CmAizpJUCbS9ONeLH/RaZg8JHhvNocyK3eAaIfMt/s1d6ldZVUgdXtp6PCvxUD8T2a0Fe1rDUy8ABCyzqvvvA4JmY/Enf1nXOgEQ/gIezzd+8H4tSatNaauFENiNYVY2V5MR678lTctXwL9rZ1B3pFBT1x8eTr0avsN8k18kp0RkCn9T8qHwz9v0hreIdOnACMx5zA/ZupqBp9TH/V1v9CDc0cKE034sX+F5mCwUcG82pzIDcTwEQ/ZIYW9tb9ubKluRk+SPhN1nPKx26U2F4XEvxJ7ckQPHwYWz9YhYP7dqJXv8EYduZEBHrEfxwk2lRMoRbMVW1p6Jr16Q48CnOzcfekiPed4I66qpKZEdDam0U5VvlZawNQNSc04xGn65Wpuj10vN1LMDpjTuTiwmxPiISTGAVK09FVml4x/mL920qQF/tfZAomnGYor+1wqHA7AUy0lHXq6KMMj+vbOwtF+dHBTGFulvZ9K+WeGj9Xel1U+LeGv5dIOePHq57Fd789HsNXX4nTP7wNw1dfie9+ezw+XvVs3LGJNhVTxAZzWu+7fW0dmPmChe87rR1m80uMZyRiEzsjgwflZ3nFGoGHwuby21gqY06kfFQJVn5cXqR5Mgbil1MSSmIUzM1JpjTdiBf7X2QKznxkIC/ucKhwOwFMtJQ1u4ff8LgHf3pS3BVhY8sh3PLiJtX7Fi33VDtOa7ko9so3+4vXcGrNTdEDBfADeQ9+sP4mfAzg1InTDW/XiNoVo+PvO6NZjGSYSGp1QyKzh2ozocqMm8LS/WFM7Lhs5+eR1q7Rdu6FQww+MpJbJ3iRKWAvJICJfhiJHhf5HFZv36N5v6LlnmrHqS0XxZ5M/JDwfs49of/X2J69uHoegj+6KrwEk8hat9YVoyvvO50NDJNiMqnVSYkEeZp5PV3f+MVZR2FCWZG1OWFduTlyS4NqhZGy43KtNAySzRUnXup/kSkYfGQgN07wovklXkkAE/0wMvuhpbfG3A+tCMo+BHzqS0qRH8YKrTVptZNJhX8rin3ayzN+H1CEPfjsg1UYftYkw/FG/p7I1bEXAkvL2FTmagWzQZ5IsPKPLY24c5LFyw8RuTkipel2vy+c2sySQhh8ZCCnT/BmpoC9lAAm+mFk5kNLa1lnor8Wj2U9oplDovZhrDXDoHUyEV3WObhvp+F4I+9/0RWnol9ujmHw5ZXA0hI2lblawWyQ5+pSZ9kUfPHDx5D3zl2Gpekp8b4gYQw+MpCTJ3izU8BWtQ/3mqAko+arPV3LLjJu/tFxWLZhBxpbDnVvaubT6Z3h8+POwK1Y1T4y/C2tGQatk4nosk6vftF9Q6xaE/dSYJmIuGXDYZMRsLjM1Qpmgzy3Z6SO/eGVOKf6Bxiy/xPV0nSvvy8oMQw+MpBVJ3iRHI5ErqqcTABzos9J1ZYG3P73zXHdQAt69cAt5x2H0+TPUPK+frWKHxJ+e9UPMUUeHhprbhYqAlsRaHsfqI9OpNQ6SSjt37W2sJdkoMnXH8POnBj3MyvWxIXfd5CAehuSRJOgvWx4BipnbbEnqTVBZoM8t2ekAn4f7p5yEmY8H/r7SJcLDtLH4CNDJXuCF83hSPSqyokEMCf6nFRtacD1z29U/VnzwcN4+K0vsfwcvZLNboG2Jow+6ZxQV8iV2u2otU4SkS3MZRnwRTyVSmJhw+i5KFLp9wEILC+ptISPPQkbvu/8G4CF7rTa1iK2bJhgUqvAc2ZWZJCnRgYw5ZTuzrNemJFixUnm8cmyrJVH5oqWlhYUFBSgubkZ+fn5bg8n7SVy5a/1Yaz8VmQOR/X2PbjiqRrDcSy9dpSjyV5mHkOigpKMsx5cg8YW/QDsx32+xOLDc41vcPprwMF96u2olZFf9hyCwyZj7II1qieTif5aPJ61MPQbkcGHciuX/Tmxk7zJ/TlU33dbVwIvTYtrsiYre7s40TFUZZxjF6zRnL1TTszrZo83HxjbvKfJ/Dfq8MTaetWf+RD9Hlf+HgD1mQendnbtOCzhz9Vf45u9BzC0sDemjj4K2T3YjipVmDl/81XNcGabA5ltAibatMvJ9VynGpnV1u81DDwAoGr/MWjvXQTtjI+uHV2HnGnQjhpof+3XgBRUbZyk5JbIiA48uo/zof21XyN4+LDhmKMo+3PEdqtU2ozXrYj7lbj3HSSgarZqd1dfxGNb/vG3qN6+x7FdRs0sG5qSwHNmRlCSseIT/cZcke9xq3ZKTkbVlgb88Hdv477X/4Xnqr/Bfa//Cz/83duuNTwkezH4IFPMfhh7sYOgbSeUGKJLThL8+KR8TtdXGs9S5YPAjg8M21HnHGjALxc8BgBxJ5NwB1WNpzry94U/8A325wAQajNutEV6V6tt7fArNLalf31RqFOnVWxJxrTqOdORyHu8srwY62aPx9JrR+GRy0dg6bWjsG72eMcCDy92XCb7MPggUxL5MPbCVZXW2Kw4TouZBL3gCZON24ELdsvs0dYUnkKPPJncO36Aqd8X+sA32J9Dq814UJJRvX0Plm/aierte3C4WezkopQLO3VSsiUZM8HnzIxE3+MJtUlPkttbKpA7mHBKpiT6YeylDoKJPgaz+TEVpYUoyu9puPRSlJ8TWnbyG7QDN9GOGuguYQ7n0tQfC6wz//u6r1ECbcbVEn1/3Ws1bhC4GWVsymnonhWf2boNgC3JmA60Zne7gsUMt7dUIHcw+CBTkvkwdqqDoFGQkMhjSKQyJuD34Z4pZZrVLop7pgzvHp9eO/ChYyB3ddU0aket+oFt0JXT8PfVmGwzrpboO9Ffi+ull1RzUdTGFqmxpR2L1mzDzecdJzaOBFx+xhA8/NaXcd9PeNnQgdbsXqhgEeV2nxFyB5ddyBQv5nBEEtnJ0+xjSGY9urK8GI9fPRJ9e8fvZtu3dxYeN7HsVFXXhDkHroYsy4idgVbrgArEfGArXTmBuLROzd9vaQPq3wM2/w3Br9ai+sum8FJJUJK7AxqjZNmhY1Sn18MN1qAdeMgaY1M8/NYXtiy/KO8ltcADSGLZ0MRzliiv/51GSqVZGrIOS20pIU70yEhkTGbKZ0Ueg1WllrEdTkcfPQCjTKypRz62if5azM16DiUR+7TskuPbUQMaJcx1K9D+2m3IOdCo+/sT/bV4tO+ymOMKMa9zGlZJFd3PlX9DV/kvoFqo2ZWzolZ2Pcpfh2XZvzV8/P9/5yX4Y/ASzZ8XJ1ruqkHrvaS45bzjceP4Y8P3Z7pkXal2AaD3nCXLi3+nsZS/MaNZGitfX7KHmfM3gw9KmCXdQS1qspRokGD0GLzQp0TtsfkhocK/VbUdNWD8gR08fBi/XPAYerQ1qf5+pb8WS7IXhm9LocyQzOichTe7ApUlV48MBSBxPSsGR7UZX75pJ25etilqHFP86/Fo9iLD5+CmjhuxQtKfCbDqNTD7Xkr4BK/a52Ow5a3ZnejiG5bg37NX+oxQcsycv5nzQQlLOofDwiZLiSatGT0GL6xHqz02CX7USGWqx4tMqwd69MCUiy5T/cAPQMJvlKWQmN9TdrCdm/VnrG4/HTL8ocTU2ZMR0EuWhfq0ueh+MyLHWfUamHkvNR/sEN40MU6ZQYKxRRzbrTWJv2d2OM08DD4ykKNXQlrC084xH9tKkyWT0852BQmi68zftbYjKMmmZlVEmR2z6Ae21gf+xLyvUNKp3ePE7wNKsAcV/q2okcqigzqtZFmoJ0Ea7Tcjw4f92QNRe2hY/A9jWJUTIPp8N7YcwkNVW4U3TVSll2CcSiz4e/ZSRRzZj8FHhvHEGrBhkyVfqMnSsEnCV4F2Ja0ZVQ0o7nv9X/jTuvrw82jl8yw65hvHHYuzjh1g6gNb7QP/zLYDwN8FxtXVcwMQO2GrbSwXud+MJCMmAAm1Ve990e8wcHlvzZJlqys3RJ/vvfvbWSIKWPr37NgsDbmO1S4ZxDNdBG1osmRXG3e9qoFYyvM4/406S59n0cd2y4TjE2oMFdtYyp9XJPR7kUshoidstYZzq6QK3JH1664W8xG6GqwFhl+Ee6aUwQdnKjdEn+/C3Gyh20v7ElEHmqZR+mHwkSE81UXQhiZLdpYWanVojaU8c0+9V2/p8+x42aRBKagkh6pjlJ4b/XpnmQrq1Np433/HHeh1W11o87xLng79O2tzeKreyS65os93UUEvodtL+xJRB5qmUfqxPfiYP38+fD4fZs2aZfddkQ69JDo/JJzpr8MZrWuwtfqNpPaUEGJTkyXlBDUoPyfq+4Pyc5I+QSknzLsnnah7nAzE9eCI/Xki+8ZonXz75WbhF2cdhYJe2dYFjhH9QGJPv2r9QPYd6MTqukaYodrGuyv/ITj8ElRLZVj+aWPUJnJO7j1SWV6Mx64ciX4xsxuRwU5FaSEG52dhlL8OU/zrMcpfBz+k8LFubJroCgeaplH6sTXnY8OGDXjyySdx8skn23k3JEBr6jeuZ8TqRcAH1m3rrcqg02aoyVJJEk2WtK5XkxPw+zAgL8f4QAGJTMVH5mesrmvEq5t2YW9bB55+/2s8/f7XwjklQomwZVNCSYIx1QuNiO8HIpRYKcgoV8apnICqLQ247/U67G3rCH+vMDcLd086Mfz8BrauxFuB29ArW70Pigx7Gnl5ImE8ku1/z5SObAs+9u/fj6uuugpPPfUUfvtb4yZCZC+1qd+J/losyVoYf3CCFSfClCvrl6YB4dRDRcQuriZLDrUaQ+1uESh7FGTVFHqitxPw+9B8sAPPvP91QuWdphJhu0pBP6uuwhOvr1ftBwLoJFaa7Pmg9foJla0KEjlxa41jX1snZr7wMZb4feHGaj1jjirCXizJWogZnbPiGr5ZwRMJ47Fs+num9GbbssvMmTMxadIknHfeebrHtbe3o6WlJeo/sl5sEl1kW+v4iyZrtvXWpVxZ6+3iaoJTOS0iyYh6F6HJTsXrPU5f1/LZ+lefQPCrtXGvXUIJx/4AtuWOwAppDGqkMtX25oqo2Zy6FcDCcuDZC4GXrwn9u7A89H2Tj8uq10+k9b7IOO5bsRly1WzIcU3qu1/7uVl/RgCSpXlUnkkYV2Px3zOlP1uCj2XLluGjjz7C/PnzDY+dP38+CgoKwv8NGTLEjiFlvNgkugr/VpT41HsrhDiQoV42BZi1RTPJ0AwzjaGSIZKMeO3ZpbZVZmg9zon+WqzLuQnLsn+Lew8/jMBzk6NO9smc3EVmafyQcGzbJmDz34B3FgAvTY2vgFBm1FQCELtfP9ETt8g4huz/BL6WXZoBqN8HlPj24Az/Vkvec4DHEsa1WPj3TOnP8uBjx44duPnmm/GXv/wFPXsaf2jNmTMHzc3N4f927Nhh9ZCoS2TSYmSPBl12Z6grTZZOujT0b4JTs052IjWqvJjz4zLbEl/Vxq8snxUh5iQXcbJP5uRuNNtT6a9Fdc+bMXz1laFZjnce0LkXqM6o2fn6mTlxi9y+6N+OcpwV7zmnguukWfT3TOnP8pyPjz76CE1NTTjttNPC3wsGg1i7di0WLVqE9vZ2BALdb8icnBzk5FiTxEfGlKTFrdWHQsmlRlIkQ93pnTENuzHKQYyUPkMPf/feKVYkvsaO33j5LNTgqWlcldDtq50o1ZqDKSr9tVictdDEI4uYUYvo7Gnn6yd64q75ao/Q7ZttCW/Fe84Lbf6JrGR58PGjH/0Imzdvjvref/3Xf2HYsGGYPXt2VOBB7gj4fRg+ujJU1ZImGepGnUit7IIZm7R44cklUcsoH696FievvweVvr1AV6XmLrkQ9+6fhhnPH0pq9iP2cSrLZ9pCJ/tjD2zWOaab1olSrRW7HxLmZf9ZdYnJUMyMmp2vn+gJeeZfNuKBn5QbjmNHn1Mg9wz97fhUjpLkUFXQBmmYZaW23Hae0o3lwUdeXh7Ky8ujvpebm4v+/fvHfZ9clGYZ6npX51Y24jKqNgh+thwjqm+KOyUVYS8WZy3EDZ2zMG9lz4TLUmMfp+gSwIl5B1BcUJjUyT12tufYtk0YtHqP6ccAAOgzKC6Iu3tSGWa+YP3rJ3pC/v5gqJrlv88pxZNr6zXHcfeUk+Dzh/52ZPiiAhAl5eLerj4oVpXaOhlcEzmBHU4zWZplqIt0wQxKMqq378HyTTujGliJ0EpabGg+hOuf34hHV2/F4dd/DTluj5Lur3+T9Wfsbj6Q1Np85OMUXQLw5xVZ0iU1sjnYiXkHzA0coY3ikD8YVftL4ypP7nu9Dv99TqnlXUyNclZirfikAY9dadBNtetvxxfzt9OI/pjROQuf5J1jaedVx7vcEtnMJ8uyi+nR8VpaWlBQUIDm5mbk5+e7PZzMYLIfg9dp9XJ449NduGv5Fuxt6wwfa6Yx19gFa3RzB0b567As27inzeUdd+GKy67ERSMGiz8ojTHVbv8PRrw8Fj0PNakuAYSXz2ZtBvwBS/tEfPb+66EkU0FKnPfKcfPxqy1D40arnDYfu/JU9MvNsbSJllbvDi1LrzkDFYGt2P7VdjTJfRE46ixUHPOD+HF0/e1IrY34V2tvbOt9Egbm59rW+MuTfT6Iupg5fzP4oIww/406PLG2XvVnPsDwKrV6+x5c8VSN7n1M8a/Ho9nGSbw3ddyIK6651bpOneHtzAHVhYKYWSzhDpkGQenyj7/FGa/+EEVQL9mWZcAX8f1dcn/c2zkVb8oVmi3oleWDdbPHW37y1nsPRJror8XC/KXodSgiLyXfuOuvU51HPdfhlKiLmfO3re3VibzgjU8bdE86Mozbg4skLYougRzOHWjt2rxGK/TQCfPBuBNmbItyZSkq6mS2daXG7XWfgAfm52Je5zQsyVoIKWapSQku/tB5Kb6RizS7o8ayaxv6oCRjxSfGTbiUsmVf7Mtt0PXXyRkJbjtP6YDBB6W1oCTjruVbDI8zOuGJJC3WSsOwSy7UnAlQqiCmTLnE+ivVrlboZpfP1E6al/fZhPmHfxe/jBNzAq4oLcSteefghlbgN1nPoSSiz4jaHjBmWF0yalRuC0SULfvUqne6y5YxbFLU8+pEW3ircfaE3JYxwQf/2DJTbf3eqM3B9Oid8IyqDQBAgl9/JsAH7B49F5UnHSH+AMxQGjwJUjtp+iHhps4/hVqH6/QNwbBJCPgDXZU3h7C6/XSc4d+KgfheeJZDj9UloyLBjGjZcmSPEqMGZlZuumcV5o2QF2REtYvIng6UnsxcQeud8CKrDfSskiowo3MWGhG9rNKI/vj87MU4deJ04fHYSeukabbtvlJ5M7CgN2qkMsM9YIz2vgGAovwcy0tGRYKZRLr+pkzn0S6e3h+GMkraz3yk4pQoWUf0CrowN8vwhKecaO9ZUYfGFu0TziqpAqvbT0dFxEzAjj6nYO24CabGLjJbl+iMntZJU/QELLU24oOIPJF3bxuHj77Zh6bWQ/j6uzY8/NaXmn0yrj071EcDUG9vd+iwhNV1jZb+XYrMXB3OHQh0avwwQjB3IJRFl1TqPJqKszSUvtI6+OAfGyknHaP1/t9eVC70HlAabS1a8yUefutLzeMk+FEjlYVPuEumnGTqPSYyNZ7M9LnWyVA0afbGlbvwRmt39Y9yv0r58AmDemPFipfRo627vfyggt7hsZ16ZD/c/vfN+P5A/Nm++UCn5RcGIk3ohlVMxN51D6Ef9qssOXXn7HwTHIbRXd9Lpc6jZmZpmNBKdkvrZZdUmxIl6yknHb3T/nXnlOLHJ5eYus2bzzsej189EsUxjahi44tEGmSJTI0nO32udTJUkma1SmFlhEpmq1qP1r7fuhWoXD0Bizt/g0ezF2FZ9m/xr8JfYd2U/ZhQVoTq7XtwsFPSfE3s2qXVqAndqM4a9MV+9THJXRcrnVPRFNEnxqiBmQ+wrMV6slJplobSX1rPfPCPjYCuk85Vp8RdiffL7Yn7LirHj09O7OpabXO504b2Cy0/tLTh2AObcWLeXvhztwHSQKHGbaKzdbIsxx3jhxRe6lmxfBsmDJuJQA/1P3GtZQgJfqw4PAbX9XgtfH+R9w8AKw6PjsvpUI5959X/wUSVSpmcA7sh/3U65vS4Dcv2j9B/EmDfVbjmhoCQ0P7GfABQnfUAgH3og9XS6fh5RODmVFt/K6TSLA2lv7QOPvjHRgC6rsRno7JzV3ijt/beRegx6SEEhic3ra/Wc2F0+/vA2/o9MrSIztbFmuivxdys57qrNTqB9j8sRuDC36nep9ZJ0w8JU3qEkknV2njLMjClRzUeCl4eF4D4uipl4FMPnWQZuKnzabyER4QrYey4MFDtk1G/HjkHGjV3yPP5gELsR2XeV6govTD0za4mbJXybrx4fg/cUtMbO1u6Z0WKbKggSaZqj/vDkJekdfCR9n9sadYW3Rbh7p/xV+L463TAZ/EeNhr3Z9SkSpHIyVZpjBUr+8Bu3ftU26nWqNzU5wNKsAcV/q2okaKrf4x+16/zu1ocuzCI2WVXy3Wn9g6d7OtWRDVhqwCwLr8EX4y+C1v7nWtLOX+yJbKpNEtD6S+tcz7SejOmuhXAwnLg2QuBl68J/buwPPT9DKO5WZwUDJ0gNBcxEOpZIQWtGYgF92f2ZBtujIX4fBOfwH1Wlhdj3ezxWHrtKDxy+QjcO36A0P2qVcWIVsqIHOd4rkSfQUKHnXLisO4AM3JmC4CvpQEnvDsTF2V/hNHH9Lc88LCiRFZk80UiJ6T1zAegfnUH2DMl6pgkr67Tie7VYO62uBNEtPimUUn5Zn3S9ydSEhp1fAKNsWJFLUPUHwusM77f2KoYPyQM8H0vMGLjihpXLgyGjgktjbU0QC14lOGDL78EGHIm8OgpqsfodUFNhtVVe5p5L6l4EUYpK+2DDyDN/tgMr66t//DzKqMeLq+eswuniNyQ4JS7Zbejc5zR1HjsY02kMZYugZNwg1yIDdKw8Pfi8k00KKWqtRG/q8apC4O4/ImJDyLw1+mIf6Z9oYCo8kFgxwfOBrSwp0SW+8OQ2zIi+ADS6I/NgqvrdCByNfjExwewWOTGBKfcLbsdg+P0ZusuP+NIPPzWF+HvifblEB6bPxBKjH1pGrROwrvHzMXAjb3R0HyoO9/EII6Xuv6d1zlVJVEVKMzNxl2TTkRRQS/DCwMrtkpQnzHrg8WjH8Gpnz2ovUHf5r+J3YFVAS1YtUfpKWOCj7RhwdV1OhC5GqxqPRrthUWh5FKtlOP8ktDVvhUMZg0AH+T8EtQcPgFNm3bqnji1ZusAYNmGb8PLMkab2SX0GA12yT21bArWTZBRu/0/GPHyLfAdMow90N6rCLc0X443YzaaU37v/p+UC810WLEvid6M2U/eHoBrxryIn/bfgRPzDsCfVxSdyG1RgGkGq/YoHTH4SDUufPh5kchVngQ/Pimfg4raWYi9ipe7TntfnHonjoUfegtUwlfaBrMGMoA5B67Csqc3hL+rd+LUmq2LXJbR28wufGqvfND8EpzBLrkBvw+je3wOHBIIcic+gF5nXo+L65rwSRK5V1ZslWA0YwYAT6/fgacBFBcUYu7kY1EZ+dwJBJiWBrTIgKo9ykhpXe2SlpQPP72eivmDLf3w8yLRq7zgCZNDV/H50SelBrkQ13fcjImr+upuMmh6U0Jl1iDm/g72GoQZHTfHNdhKZEOv2IoFZTO7//hiApX8kuSSj5Vdck+6NPRvbAAjOrvWZxDgD8RV1iy9dhTWzR4fFzCoVS+JBA0iHVGNZswiqb42SoAJQLOGLpFgT0daV+1RxvLJsmxd/2ILtLS0oKCgAM3NzcjPz3d7ON4UrnYBVKv107DaJXb24bSh/fDD371teDW4bvb40IeyFETtOyvx/Fsb4rZ8D++/EnPlrHWlrXV8lIgeLMHcgThn2aGoBlS6YxUUNyMztACBHdXO9X2pfy9U4m1k+mvC+UdayyqxuS5all47Sje3a/mmnbh52SahsQA6r01Mnw8AoaBfyQ2xgRVLTkR2MnP+5rJLKjJYk0+3wEPrQ3fKKcV4cm29UMOkIPy4+YM8NEjxM0Jq5YpJlzcqswYAarfvwc6WmvhjIm7PdCtxKYjAN+sx+sBuoCAi0HAyydjiJQi9ZRWRwAMwXo4zmxeh+doYLEvZIa2q9ijjMfhIVQ5/+FlRYZAIvRPSk2vr8d/nlGLFJw2GeQRmyxWtLG+0vFpB9apbrH27pQxyXAAIL0GILKuIMAouzPZRUai+Nk4He0ijqj3KeAw+UplDH35uTfeKzD6s+KQB7942LrSZm05gZDYAsDJgsLRawWsN5iyahTOTi6FGNOlSr4+KHlaSEFmLwQfpsqLCwIjWrIro7MNH3+wzvBo0GwBYGTCIXG0X5ecYVyt4tcGcBbNwZnpUJLsviZKwe/vfN+P7A+p5OJG3zUoSIusx+MgwZpZPrG7rrEZvVqX9sKTzm91ETlxmyxWtLG8Uudo+dFjC6rpG/UDOyw3mkpyFEw32bjnvOCzbsMN0uW7s+16SZKHAA2AlCZEdGHxkELPLJ3a0dY4dj96syqzzjhe6HZETl9kdPa3eAdToarv5QKfxTFIaN5gTDfZuHH8cbhx/nKn8I7X3vcjLltL7PxF5HPt8ZIhEdsW0s62zSILhsg3foig/R6+jiamdT83u6Gn1DqATyorQs4f6UoRQr4o0bjBnppeFknR50YjBhrvHar3vDdqBAAB+f+kpDDyIbMKZjwyQ6PKJnW2dRWdVbjnvOCx860tLZh8A8+WKVpU3BiUZ//t+PRpbkphJcqG7ppOs3oFa730v4ru29gR/k4iMMPjIAIkun9jZ1ll0tuSoAbmWnpAA8+WKyZY3qk3769F8brpKW+WXpkFG9LSlhNDr4bO4u6bTrOxlkWwFDStciOzD4CMDJLp8opb34IeECv9WDMT3aEJf/PzCKxI6MZiZVRl9TP+Uba6kldeiR++5qZLOwKsdN+M3MVvYN8r9cW/nVFwsnYHKJMarxukeL1b1skh0l1dWuBDZj8FHBkhm+SRyKvzk1rWYG3PSw+r/AQLmm1uZnVVJxeZKHYcl3PHKZuHAw+ikpywjNEgVeLP99KggsFYaBhl+fJJk9VGsVG7pncjMBStciJzBhNMMoJzoE03crCwvxrop+/F49iMojgw8gO7mVnUrTI0p3TfLqtrSgFHz/4m9bfrlnAqRxxy5jCDBjxqpDCukMaiRyiDBH7V8ZoVEkpTNUttEzipG73sgvuol0WRiIjKHMx8ZIOmyUSmIwKrbYXVzK6sTDL0ikaUWkcdsZ/VRLLd7vFjx2ou87xddMRL9crNTbjmPKNUx+MgQSZ3obWxulW6bZSVSYXH3pBPx87NKDR+zndVHsdzu8WLV7EO6BrhEqY7BRwZJ+ERvc3OrVMzn0GKmwkLJ8RAJPADrqo9EEkjd7PFixaxKpHQLcInSAYOPDJPQiT6Nm1sBCO2ZYtHuwGZPxmbyWqzouiq61OGFHi+JzqqoSacAlygdMOGUjCnNrfRSVvMH6za3sjOxMCl1K4CF5cCzFwIvXxP6d2G56QRahejJuDA3K6GlhWS6rppJIE02SVmPk7krRORNnPkgY13NrUJbuWtcc+s0t/JsuaaF29MrSxmNzQdRmJuNfW0dmnkf/XOzUT3nR8jukVjsn8gygtmlDqv3tonkZO4KEXkTZz5ITNmU0Mk4PyZYyC/RPUk7Ua6ZEMPt6RGq4JGChjdVtaUBYxeswRVP1eCWlz7BXo3Aw9f13/0/KU848FCY2d8EMLfUobB6bxuFnbMqtpKCQP17wOa/hf4VeG8QkTrOfHiU010lhZRNCZXTCuZHOJ1YaIpFFTxmymrdrLBIdKnDjmRNO2dVbFO3IhSsRr5n8ktCM4ImG+wREYMPT/LsMgUQCjQEy2ndSCwUZkEFj0hZbWFuFu6+cDiK8t0NIJNZ6rAjWTOlSmAtXJ4johAGHx7jVP8DJ3g6sdCCCh6Rstq9bZ0oyu/peqWFnZsEJioVSmCDhw/j8Gu3IRuyyjJR4g32iDIdcz48xGiZAggtU3imUsSApxMLLajg8XRwFSPg9+HuSWWagQfgzlKH2dwVJ1VtacAvFzyGnAONOi3aI5bniEiY5cHH/PnzccYZZyAvLw8DBw7ExRdfjM8//9zqu0lLiSQFepmnEwuVCp7wSCIZV/AAHg+uYlRtacB9r9ep/oz7mcRTZiB7tDWJ/UKCDfaIMpXlwce7776LmTNnoqamBqtXr8bhw4dx/vnno62tzeq7SjupdCUtwvObx+lV8Jw7Bwh26FY1eDq4iqBVcaS4e9KJDDwiRM5ANqGv2C+laoM9IpdYnvNRVVUV9fUzzzyDgQMH4qOPPsI555xj9d2llVS6khbl+cTC2AqePduBj54B3nmg+xiNqga7qzasqHgySor1Abjv9X9hYnmxp5Y83BQ5A1krDcMuuRBF2Bu3A26IL/T+0FmeI6J4tiecNjc3AwAKC9Wv/trb29He3h7+uqWlxe4heZYXkwKt4PnEQqWCp24F8M58mKlqsCu4Ml3xpNEi3tMVRx4VObMowY95ndOwJGshJBlRAYgMXyjINFieI6J4tgYfsizj1ltvxdixY1FeXq56zPz58zFv3jw7h5EyUrL/gSDP761h2HQsuqohdlbi3dvG4aNv9pkOrtRmN1bXNQpXPAUlGdvefQFHfjAPvQ5F5B10zdY0dZwm9PAtX8qzcL8cp8XOLK6SKjCjcxbmZj2HEnTnW3X0LkLOhQ+xzJYoAT5Zlm0rnZg5cyZef/11rFu3DkcccYTqMWozH0OGDEFzczPy8/PtGpqnebrPR7qqfy+0r4uR6a+hqu1YS14ftde5KL8nDh0O4vsDnZq/V5ibhZo552HN1t1459X/wQOdDwFAzLJA6IvPf/gYJq7qaziWpdeOsi44TPGGXEFJxtgFa+JmIP2QUOHfioH4HodzB+KPs2ci0IPdCogULS0tKCgoEDp/2xZ8/PKXv8Srr76KtWvXorS0VPj3zAw+nXmyw2k62/y30MZyBj6p+D0uXlsSNyuhvDKiVSNmOqOq6ZPTAwfaO7Au5ybdfAQ5vwRjDy3ErpZO3aW8dbPHW/P+0mrIpTxDKdKQS3l9APUZSFYHEcUzc/62vNpFlmXceOON+Pvf/441a9aYCjyom5f7H5iSKvthCFYrPPHxgaT7sIh0RjWyv/0wKvxbUeLTCjxCo/K17MTDow4AcKDiyML9ctxm1742RBRi+ZzhzJkz8cILL2D58uXIy8tDY2MjAKCgoAC9evWy+u7Iy1Jp+l1pOtbSAPWTpw/tvYtQtfdozZsQTd4U6YwqYiC+Fzqu4geHseTqM+2vOLJovxyv8HyiNFEKszz4WLJkCQDg3HPPjfr+M888g5///OdW3x15ldP7YSSb4Kg0HXtpGqCR7vtJ+e2Q1hpPFholb1qV3GmmB0VlqQMnUgv2y/EazydKE6Uoy4MPG/NXKVWYrBxJmlUzLErTMdXbehDBnLOAtTWGN2PUh0Xv55FJjU3oi1ppGCSN1VGjHhQyfPBF9KCw/URqwX45jkrhihyiVMdUbbKek9PvVs+wxDYdizgpVUiyJX1YtPq5TPTXhso5fd3lnLvkQszrnIZVUkXc7ej1oJC6xuNoDwqBpSvPNORKpSVBojTEjeXIek5Nv9uV4Kg0HTvp0tC/XSdvq9rFq93ORH8tlmQtRBGi9+0pwl4syVqIif5a1dtSelA0Ijrgae9VBJ/TlSUW7JfjCCVgjQ2QlYC1boU74yLKIAw+yHpOTb+bmWFJRkTFTmXuNiy56pSkqyAiqyn8kDA36zkAsb06ur+em/Vn+CGp3tYqqQJj2x/F5R134aaOG3F5x13Y9NP33LmC19svxwtltmlUkUOUyrjsQtZzavrdiRkWlen5yvwSTJjyIGp7jk0qeVOppvjb315ASZ32TsV+H1CCPajwb0WNVKZ6jAR/1M+uaNNuUmY7naUr16VZRQ5RqmLwQdYTqByxZPrd7hkWnXySwF+nY/RlzwEjkruSD/h9OLWwQ+jY607tjdPzj8Wit7cZHuv65oPK0pXXpGFFDlEq4rIL2cOJ6XdlhkVvU/v8wYnNsDg4PX/M0ccIHXfOaSfhlgnHo7igp94jRnEKbj7omFSryCFKUww+yD5lU4BZW4DprwGXPB36d9Zm69b97UxwdCqfBEDgqLNwsFcRtBqjSjJwsFcRAkedZVnSa8ayM2AlImEMPsheGpUjlrFrhsXJ6Xl/AL0m/w4+ny8upVQC4PP50Gvy78LPHVt/JyFVKnKI0pytu9omghvLUUKsbhhlYpdby3Ib6lZArpoNX8SMi5w/GL7KB1WDKG4+mATVPh+DQ4GH2xU5RCnKE7vaJorBB3mCFAQWlhtX7MzabO1VstNdNzO5y2cmP3YiG5g5f7PahUiNUxU7avfrVJVIpnf59GpFDlEGYM4HpZ2gJKN6+x4s37QT1dv3GG5xr8nrDbOSwS6fROQiznxQWqna0hC3dXxxMlvHe7lhVqKc3viPiCgGZz4obVRtacCM5zdGBR4A0Nh8CDOe34iqLQ2J3bDdFTtOc7CMmIhIDYMPSgtBSca8lXV6LcEwb2Vd4ksw6YRdPonIZQw+KC3U1u+Nm/GIJANoaD6E2nrtPVQyBrt8EpHLGHxQWmhq1Q48EjkurbHLJxG5jMEHuS9iy3rUv5fQfimiG6m5vuGaF7DLJxG5jNUu5C6Lek1UlBaiuKAnGpsPabUEQxE3XOumlBGrPvfs8klE9mKHU4+wpFV2qnVs1NqyXrn6NtlLQ6l2AVRbgnHfEzWp9p4hIs9ie/UUo9Wb4u5JZeiXmy0WkKRat8pw+3Ktks/E2pdb3ueDiIiEMPhIIcrVusiLoHkStXgGQVRSszU2btzGDdeIiJzHvV1ShF5vCjVKs6yo5YMEu1Ume4JOeoahVbDhVwK9JgJ+H0Yf09/07xERkTMYfLjIqDdFrK5QAvNW1mFCWVEoWDDTrbJrBiHZwEFrtkY1OFJTtwKommN4PwDYa4KIKA2x1NZFifSciGuWZbJbZbItyJPuJKosER34zmDA7DVBRJSuGHy4KJmeE+HAxUS3SitakCfVSVR3iUgFe00QEaUlBh8uUnpTJJIKGQ5cTHSrtKIFeVKdRA2XiLr0HpD6W9YTEZEmBh8uCvh9mDu5DIB26BDLh1B+RrhZlolulVa0IE+qk6joElHl/LQIPIKSjOrte7B8005Ub9/DTe2IiLow4dRlleXFWHL1yLgEUDVKaDF3cll0ZYpgt0orWpAn1UlUdIkoL/X7cbDfCBGRNvb58IjY0td9be247/V/mTt5GXSrDEoyxi5YYxg4rJs9XrfsNuFOouHGYg1Qz/tIrLGY12hVA7HTKhGlMzYZSxN2NMuyqgV5wlf24YZoGiNI8VwPJcDTmsUSDfCIiFINgw/SZdWSQMLBkWor+MGWbWjmZofT6u17cMVTNYbHLb12lCcbobE7LBElih1OSVdleTEmlBUlfZJJuJNo2ZRQx1UbNjRzO9fCiqRet7j93BFR5mDwkaFcb0HuD5jes8VI0p1XLWBFUq8bvPDcEVHmYKktpQUrGqhZwah3S1yptAd45bkjoszB4IPSghUN1Kyg17tFs1TaZV557ogoczD4oLTgpVwLpXdLUUH00kpRQU9PLl946bkjoszAnA9KC17LtbAqqdcJXnvuiCj9MfigtJBU51WbuJ7UK8iLzx0RpTcuu1BaSMVcC6/gc0dETmPwQWkj1XItvITPHRE5iR1OKe2wS2fi+NwRUaLMnL9tm/lYvHgxSktL0bNnT5x22ml477337LoroihKrsVFIwZj9DH9efI0gc8dETnBluDjxRdfxKxZs3DnnXfi448/xtlnn40LLrgA3377rR13R0RERCnElmWXM888EyNHjsSSJUvC3zvxxBNx8cUXY/78+bq/y2UXIiKi1OPqsktHRwc++ugjnH/++VHfP//887F+/fq449vb29HS0hL1HxEREaUvy4OP7777DsFgEIMGDYr6/qBBg9DY2Bh3/Pz581FQUBD+b8iQIVYPiYiIiDzEtoRTny86UU2W5bjvAcCcOXPQ3Nwc/m/Hjh12DYmIiIg8wPIOpwMGDEAgEIib5WhqaoqbDQGAnJwc5OTkWD0MIiIi8ijLZz6ys7Nx2mmnYfXq1VHfX716NcaMGWP13REREVGKsWVvl1tvvRVTp07F6aefjtGjR+PJJ5/Et99+i+uvv96OuyMiIqIUYkvw8X/+z//Bnj17cO+996KhoQHl5eV44403MHToUDvujoiIiFII26sTERFR0jzRXp2IiIhIDYMPIiIichSDDyIiInIUgw8iIiJyFIMPIiIichSDDyIiInIUgw8iIiJyFIMPIiIichSDDyIiInIUgw8iIiJyFIMPIiIichSDDyIiInKULbvaEllGCgLfrAf27wb6DAKGjgH8AbdHRURESWDwQd5VtwKomg207Or+Xn4JULkAKJti+OtBSUZt/V40tR7CwLyeqCgtRMDvs3HAREQkgsEHeVPdCuClaQDk6O+3NIS+f9lzugFI1ZYGzFtZh4bmQ+HvFRf0xNzJZagsL7Zp0EREJII5H+Q9UjA04xEbeADd36u6PXSciqotDZjx/MaowAMAGpsPYcbzG1G1pcHa8RIRkSkMPsh7vlkfvdQSRwZadoaOixGUZMxbWacXtmDeyjoEJbUjiIjICQw+yHv27074uNr6vXEzHpFkAA3Nh1BbvzfBwRERUbIYfJD39BmU8HFNrdqBRyLHERGR9Rh8kPcMHROqaoFWZYoPyB8cOi7GwLyeQnchehwREVmPwQd5jz8QKqcFEB+AdH1d+aBqv4+K0kIUF/TUC1tQXBAquyUiIncw+CBvKpsSKqfNjymLzS/RLbMN+H2YO7kMgGbYgrmTy9jvg4jIRT5Zlj2V9t/S0oKCggI0NzcjPz/f7eGQ2xLscMo+H0REzjJz/mbwQWmLHU6JiJxj5vzNDqeUtgJ+H0Yf09/tYRARUQzmfBAREZGjGHwQERGRoxh8EBERkaMYfBAREZGjGHwQERGRoxh8EBERkaMYfBAREZGjGHwQERGRoxh8EBERkaM81+FU6fbe0tLi8kiIiIhIlHLeFtm1xXPBR2trKwBgyJAhLo+EiIiIzGptbUVBQYHuMZ7bWE6SJOzatQt5eXnw+cxvAtbS0oIhQ4Zgx44d3JhOAJ8vc/h8mcPnSxyfK3P4fJnjxPMlyzJaW1tRUlICv18/q8NzMx9+vx9HHHFE0reTn5/PN6QJfL7M4fNlDp8vcXyuzOHzZY7dz5fRjIeCCadERETkKAYfRERE5Ki0Cz5ycnIwd+5c5OTkuD2UlMDnyxw+X+bw+RLH58ocPl/meO358lzCKREREaW3tJv5ICIiIm9j8EFERESOYvBBREREjmLwQURERI5K6+BjypQpOPLII9GzZ08UFxdj6tSp2LVrl9vD8qSvv/4a11xzDUpLS9GrVy8cc8wxmDt3Ljo6Otwemmfdf//9GDNmDHr37o2+ffu6PRzPWbx4MUpLS9GzZ0+cdtppeO+999wekmetXbsWkydPRklJCXw+H1599VW3h+RZ8+fPxxlnnIG8vDwMHDgQF198MT7//HO3h+VZS5YswcknnxxuLjZ69Gj84x//cHtY6R18jBs3Di+99BI+//xzvPzyy9i+fTsuvfRSt4flSVu3boUkSXjiiSfw2Wef4eGHH8bjjz+OO+64w+2heVZHRwd+9rOfYcaMGW4PxXNefPFFzJo1C3feeSc+/vhjnH322bjgggvw7bffuj00T2pra8Mpp5yCRYsWuT0Uz3v33Xcxc+ZM1NTUYPXq1Th8+DDOP/98tLW1uT00TzriiCPw4IMP4sMPP8SHH36I8ePH46KLLsJnn33m7sDkDLJ8+XLZ5/PJHR0dbg8lJTz00ENyaWmp28PwvGeeeUYuKChwexieUlFRIV9//fVR3xs2bJh8++23uzSi1AFAfuWVV9weRspoamqSAcjvvvuu20NJGf369ZP/9Kc/uTqGtJ75iLR371785S9/wZgxY5CVleX2cFJCc3MzCgsL3R4GpZiOjg589NFHOP/886O+f/7552P9+vUujYrSVXNzMwDws0pAMBjEsmXL0NbWhtGjR7s6lrQPPmbPno3c3Fz0798f3377LZYvX+72kFLC9u3b8cc//hHXX3+920OhFPPdd98hGAxi0KBBUd8fNGgQGhsbXRoVpSNZlnHrrbdi7NixKC8vd3s4nrV582b06dMHOTk5uP766/HKK6+grKzM1TGlXPBxzz33wOfz6f734Ycfho+/7bbb8PHHH+PNN99EIBDAtGnTIGdQU1ezzxcA7Nq1C5WVlfjZz36G//t//69LI3dHIs8XqfP5fFFfy7Ic9z2iZNx444349NNPsXTpUreH4mknnHACNm3ahJqaGsyYMQPTp09HXV2dq2Pq4eq9J+DGG2/E5ZdfrnvMUUcdFf7/AQMGYMCAATj++ONx4oknYsiQIaipqXF9yskpZp+vXbt2Ydy4cRg9ejSefPJJm0fnPWafL4o3YMAABAKBuFmOpqamuNkQokT98pe/xIoVK7B27VocccQRbg/H07Kzs3HssccCAE4//XRs2LABjzzyCJ544gnXxpRywYcSTCRCmfFob2+3ckieZub52rlzJ8aNG4fTTjsNzzzzDPz+lJsYS1oy7y8Kyc7OxmmnnYbVq1fjJz/5Sfj7q1evxkUXXeTiyCgdyLKMX/7yl3jllVfwzjvvoLS01O0hpRxZll0/D6Zc8CGqtrYWtbW1GDt2LPr164evvvoKv/nNb3DMMcdkzKyHGbt27cK5556LI488Er///e/xn//8J/yzoqIiF0fmXd9++y327t2Lb7/9FsFgEJs2bQIAHHvssejTp4+7g3PZrbfeiqlTp+L0008Pz6J9++23zCHSsH//fmzbti38dX19PTZt2oTCwkIceeSRLo7Me2bOnIkXXngBy5cvR15eXniGraCgAL169XJ5dN5zxx134IILLsCQIUPQ2tqKZcuW4Z133kFVVZW7A3Oz1MZOn376qTxu3Di5sLBQzsnJkY866ij5+uuvl//973+7PTRPeuaZZ2QAqv+RuunTp6s+X2+//bbbQ/OExx57TB46dKicnZ0tjxw5kqWQOt5++23V99L06dPdHprnaH1OPfPMM24PzZN+8YtfhP8Of/CDH8g/+tGP5DfffNPtYck+Wc6g7EsiIiJyXeYt6hMREZGrGHwQERGRoxh8EBERkaMYfBAREZGjGHwQERGRoxh8EBERkaMYfBAREZGjGHwQERGRoxh8EBERkaMYfBAREZGjGHwQERGRoxh8EBERkaP+H90AaTrghz+bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nuevamente generamos los datos aleatorios con una desviación estandar conocida\n",
    "# Alrededor de una funcion lineal conocida y = 1.2x + 0.7\n",
    "n_samples = 300\n",
    "ruido_blanco_std = 2\n",
    "X = np.random.randn(n_samples, 1)\n",
    "for_bias = np.ones([n_samples, 1])\n",
    "X_augmented = np.concatenate([for_bias, X], axis=-1)\n",
    "eps = np.random.randn(n_samples, 1) * ruido_blanco_std\n",
    "ideal_w = [[5], [1.2]]\n",
    "target_y = X_augmented @ ideal_w + eps\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "n_val_dp = n_samples//3\n",
    "x_train = X_augmented[:-n_val_dp,:]\n",
    "y_train = target_y[:-n_val_dp]\n",
    "\n",
    "x_val = X_augmented[-n_val_dp:,:]\n",
    "y_val = target_y[-n_val_dp:]\n",
    "\n",
    "print(target_y.shape, y_train.shape, y_val.shape, x_train.shape)\n",
    "# Graficar set de entrenamiento\n",
    "plt.scatter(x_train[:,-1], y_train)\n",
    "plt.scatter(x_val[:,-1], y_val)\n",
    "#plt.scatter(X, target_y)\n",
    "\n",
    "#print(\"targety\", target_y)\n",
    "#print(\"y_train\", y_train)\n",
    "#print(\"y_val\", y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida\n",
    "Ya que hemos cargado el dataset y sabemos como está compuesto, debemos calcular la función de pérdida\n",
    "\n",
    "$ MSE = J(w) = \\frac{1}{2n} \\sum_{i=1}^{n} (\\hat{Y}_i - Y_i)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.99541242432326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_loss(y, y_pred):\n",
    "    \"\"\"\n",
    "        Regresa el error cuadrático promedio de todas las predicciones\n",
    "        y: shape=N Etiquetas\n",
    "        y_pred: predicciones del modelo\n",
    "    \"\"\"\n",
    "    # TODO: Calcula el resultado de la función de pérdida\n",
    "    # ====== Start of solution =====\n",
    "    \n",
    "    loss = np.mean((y-y_pred)**2)\n",
    "    return loss\n",
    "    # ====== End of solution =====\n",
    "# Iniciamos con unos parametros w arbitrarios\n",
    "w = np.random.uniform(-10, 10, size=(2, 1))\n",
    "# TODO: Calcula las preddiciones para el conjunto de entrenamiento x_train\n",
    "y_pred = x_train @ w \n",
    "\n",
    "\n",
    "#y_val = np.concatenate([for_bias, X], axis=-1)\n",
    "#loss = (1/(2*n_val_dp)) * pow((y_val - target_y),2)\n",
    "#print(target_y.shape,y_val.shape)\n",
    "\n",
    "# TODO: Calcula la función de pérdida para las predicciones(y_pred) y los valores reales (y_train)\n",
    "# ====== Start of solution =====\n",
    "mse_loss(y_train,y_pred)\n",
    "\n",
    "# ====== End of solution ====="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar como se ve la función de pérdida con diferentes pesos.\n",
    "Si elegimos los pesos que generan la menor pérdidda en el set habremos encontrado los parametros ideales para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (200,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25864\\2134873951.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# ====== Start of solution =====\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcalc_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m# ====== End of solution =====\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (200,2) "
     ]
    }
   ],
   "source": [
    "# Probaremos con 100x100 combinaciones de distintos parametros\n",
    "w0 = np.linspace(-10, 10, 100)\n",
    "w1 = np.linspace(-10, 10, 100)\n",
    "w0w0, w1w1 = np.meshgrid(w0, w1)\n",
    "w0_flat = w0w0.ravel()\n",
    "w1_flat = w1w1.ravel()\n",
    "W = np.stack([w0_flat, w1_flat], axis=0)\n",
    "\n",
    "\n",
    "# Calculamos la función de pérdida\n",
    "# TODO: calcula el costo de las predicciones (y_pred) contra etiquetas (y_train)\n",
    "# usando las 100x100 combindaciones de parametros (W)\n",
    "# ====== Start of solution =====\n",
    "y_pred = x_train @ W\n",
    "calc_cost = 1/(2*len(y_pred))*np.sum((y_pred-(w0+w1*x_train)**2))\n",
    "# ====== End of solution =====\n",
    "\n",
    "# Graficamos los parametros w con su respectivo costo en el eje de las x\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(w0_flat, w1_flat, calc_cost)\n",
    "\n",
    "# TODO: Escribe a qué valor corresponde cada eje\n",
    "# ====== Start of solution =====\n",
    "ax.set_xlabel(...)\n",
    "ax.set_ylabel(...)\n",
    "ax.set_zlabel(...)\n",
    "# ====== End of solution =====\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos encontrar la combinación de pesos que minimizan la pérdida\n",
    "# Y de esta manera encontrar los pesos ideales\n",
    "best_idx = np.argmin(calc_cost)\n",
    "search_w0 = w0_flat[best_idx]\n",
    "search_w1 = w1_flat[best_idx]\n",
    "search_w = [[search_w0], [search_w1]] \n",
    "\n",
    "plt.scatter(X, target_y)\n",
    "# TODO: Grafica la línea de regresión generada por tu modelo search_w\n",
    "# Encima de las muestras dadas\n",
    "# ====== Start of solution =====\n",
    "pred_y = ...\n",
    "plt.plot(...)\n",
    "# ====== End of solution ====="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterior evaluamos $100 \\times 100$ combinaciones de pesos posibles y encontramos los mejores pesos. En este caso solo tenemos 2 parametros que queremos estimar, por lo que encontrar la solución de esta manera es factible al tener que realizar alrededor de $100^2$ evaluaciones de la función. \n",
    "\n",
    "<b>TODO: Contesta las siguientes preguntas</b> \n",
    "- ¿Cuántas evaluaciones de la función de pérdida tendríamos que hacer si tuviéramos 4 parametros?\n",
    "- ¿Qué pasaría si tuviéramos 1 millon de parametros?\n",
    "\n",
    "Las redes neuronales tienen millones de parametros para hacer predicciones, por lo que encontrar la solución de esta manera no es factible. Se han encontrado formas más eficientes de encontrar la solución por ejemplo, a través de métodos iterativos. Uno de ellos es decenso de gradiente. Siguiendo la direccion contraria del gradiente de la pérdida con respecto a los pesos, podemos encontrar los parámetros que <b>minimizan</b> la función de pérdida utilizando menos evaluaciones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso de gradiente\n",
    "En esta sección, optimizarás la función de regresión lineal a través de descenso de gradiente.\n",
    "La predicción de nuestro modelo está dada con la siguiente funcion:\n",
    "\n",
    "$ \\hat{Y}_i = w_0 + w_1 * x$\n",
    "\n",
    "$\\hat{Y} = \\mathbf{X}\\mathbf{w}$\n",
    "\n",
    "<!-- El gradiente de MSE con respecto a $w_0$ se calcula de la siguiente manera\n",
    "\n",
    "$ \\frac{\\partial J(w)}{\\partial w_0} = \\frac{\\partial J(w)}{\\partial \\hat{Y}_i} * \\frac{\\partial \\hat{Y}_i}{\\partial w_0}= \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{Y}_i - Y_i) $\n",
    "\n",
    "El gradiente de MSE con respecto a $w_1$ se calcula de la siguiente manera\n",
    "\n",
    "$ \\frac{\\partial J(w)}{\\partial w_1} = \\frac{\\partial J(w)}{\\partial \\hat{Y}_i} * \\frac{\\partial \\hat{Y}_i}{\\partial w_1} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{Y}_i - Y_i) * x_i $ -->\n",
    "\n",
    "Donde:\n",
    "- $\\hat{Y}_i \\in  \\hat{Y}$\n",
    "- $\\mathbf{Y} \\in \\mathbb{R}^{N}$\n",
    "- $\\mathbf{X} \\in  \\mathbb{R}^{N \\times D}$ en notación aumentada\n",
    "- $\\mathbf{w} \\in \\mathbb{R}^{D}$ en notación aumentada\n",
    "\n",
    "Como vimos en clase, el gradiente la función de costo con respecto a los pesos está dado por:\n",
    "\n",
    " $\\frac{\\partial J(\\mathbf{w})}{\\partial \\mathbf{w}} = -\\frac{1}{N}X^T\\epsilon$\n",
    "\n",
    " donde $\\epsilon=\\mathbf{Y}-\\mathbf{X}\\mathbf{w}$\n",
    "\n",
    " TODO: Completa el código necesario para aplicar descenso de gradiente durante n_iteraciones. Para ello realiza los siguientes pasos:\n",
    "- Calcula el valor de las predicciones $\\mathbf{Y}$\n",
    "- Calcula el gradiente de la función a optimizar $\\frac{\\partial J(\\mathbf{w})}{\\partial \\mathbf{w}}$\n",
    "- Actualiza los pesos con el gradiente $\\mathbf{w}^{i+1} = \\mathbf{w}^{i} - \\alpha \\frac{\\partial J(\\mathbf{w})}{\\partial \\mathbf{w}}$\n",
    "- Repite hasta optener el valor óptimo de $\\mathbf{w}$\n",
    "\n",
    "Es tiempo de programarlo en código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr, N_iterations, w_start=np.array([0,0])):\n",
    "    \"\"\"\n",
    "    Entradas:\n",
    "    X: arreglo con los datos en notación aumentada X\n",
    "    y: vector de etiquetas\n",
    "    lr: ritmo de aprendizaje\n",
    "    N_iterations: cantidad de iteraciones de optimización\n",
    "    w_start: pesos iniciales\n",
    "        \n",
    "    Regresa:  \n",
    "    w_opt: pesos óptimos\n",
    "    cost_history: arreglo con el valor de costo para cada iteración\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # initialize the coefficients\n",
    "    w=w_start\n",
    "    \n",
    "    for i in range(N_iterations):\n",
    "        # ====== Start of solution =====\n",
    "        # TODO: Calcula la predicción \n",
    "        hypothesis = ...\n",
    "\n",
    "        # TODO: Calcula el error\n",
    "\n",
    "\n",
    "        # TODO: Calcula el gradiente del MSE loss\n",
    "\n",
    "\n",
    "        # TODO: Actualiza los pesos\n",
    "\n",
    "        \n",
    "        # ====== End of solution =====\n",
    "        # Calculamos la función de pérdida y guardamos el resultado\n",
    "        loss = mse_loss(y, hypothesis)\n",
    "\n",
    "    print(f\"Total de evaluaciones {i}, la pérdida final fue {loss}\")\n",
    "    w_opt=w\n",
    "    return w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Parámetros de descenso de gradiente\n",
    "N_iterations = [50,60,80]\n",
    "\n",
    "# Pesos iniciales y ritmo de aprendizaje\n",
    "lr = 0.1  # Utiliza valores cercanos e.g. 0.05, 0.2 .. etc\n",
    "w_start = np.array([-400,0])\n",
    "w_start = np.expand_dims(w_start,-1)\n",
    "\n",
    "# (2.) - (4.) -> Variación de cantidad de iteraciones\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(x_val[:,-1], y_val)\n",
    "for n_it in N_iterations:\n",
    "    # Entrenamos el modelo en el set de entrenamiento\n",
    "    w_opt = gradient_descent(x_train, y_train, lr, n_it, w_start)\n",
    "\n",
    "    # Visualizamos la predicción en el set de validación\n",
    "    prediction = x_val @ w_opt\n",
    "    plt.plot(x_val[:,-1], prediction, label = str(n_it)+\" Iteraciones de GD\", linewidth=3)\n",
    "\n",
    "# Obtener la solución analítica\n",
    "analitic_sol=linear_model.LinearRegression()\n",
    "analitic_sol.fit(x_train, y_train)\n",
    "\n",
    "# Visualizar solución analitica\n",
    "plt.plot(x_val[:,-1], analitic_sol.predict(x_val),label = 'Solución analítica', linewidth=1, linestyle=\"dashed\", color=\"black\")\n",
    "# plt.ylim(bottom=-10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TODO: Contesta las siguientes preguntas</b> \n",
    "- ¿Cuántas evaluaciones de la función de pérdida se evaluaron para encontrar la solución con un $lr=0.1$? ¿Cómo se compara este número a la solución por busqueda exhaustiva? \n",
    "- ¿Qué pasa si cambiamos la tasa de aprendizaje (lr) a un valor dos veces grande?\n",
    "- ¿Qué pasa si cambiamos la tase de aprendizaje a un valor dos veces más chico?\n",
    "- ¿Qué pasa si cambiamos la tasa de aprendizaje (lr) por un valor muy grande?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística\n",
    "En este ejercicio exploraremos el uso de Regresión logística. Primero programarás los elementos necesarios para optimizar la función por descenso de gradiente y después usaremos las librerias de scikit-learn para encontrar la solución. \n",
    "\n",
    "Regresión logística nos sirve para resolver problemas de <b>clasificación</b>, esto consiste en utilizar datos para estimar un valor discreto que será asignado a una categoría, en el siguiente código nos enfocaremos especificamente en clasificación \n",
    "binaria.\n",
    "\n",
    "Para entender mejor los conceptos utilizaremos el [\"Breast cancer wisconsin (diagnostic) dataset\"](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer). Este dataset contiene distintos atributos para determinar si un tumor es maligno(0) o benigno(1). Antes de empezar analizaremos el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "# Podemos visualizar los atributos del dataset y la dimensionalidad de los datos\n",
    "print(\"Nobres de las columnas:\", dataset.keys())\n",
    "print(\"Matriz de datos (X.shape -> NxD): \", dataset['data'].shape)\n",
    "print(\"Cantidad de datos(N): \", dataset['target'].shape)\n",
    "print(\"Clases: 0-> %s, 1-> %s\" %(dataset.target_names[0], dataset.target_names[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos visualizar los nombres de los datos para decidir que atributos utilizar.\n",
    "# En este caso utilizaremos la textura y el perímetro del tumor para generar la predicción.\n",
    "print(dataset['feature_names'][[21, 22]])\n",
    "print(dataset['target_names']) \n",
    "\n",
    "# Haremos el split de los datos y a partir de ahora solo usaremos\n",
    "# el conjunto de entrenamiento para encontrar nuestro modelo\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    dataset['data'][:, [21, 22]], \n",
    "    dataset['target'], \n",
    "    test_size=0.25\n",
    ")\n",
    "\n",
    "# TODO: Imprime la cantidad de puntos que serán dedicados para entrenamiento y\n",
    "# para prueba\n",
    "# ====== Start of solution =====\n",
    "print(f\"Entrenamiento - {...} datapoints\")\n",
    "print(f\"Evaluación - {...} datapoints\")\n",
    "# ====== End of solution =====\n",
    "\n",
    "# Es bueno saber como es la distribución de los datos\n",
    "# Incluyendo cuantos ejemplos son benignos y malignos\n",
    "malignant_idcs = np.where(target_train == 0)\n",
    "benign_idcs = np.where(target_train == 1)\n",
    "\n",
    "# TODO: Imprime la cantidad de puntos que son malignos y benignos\n",
    "# ====== Start of solution =====\n",
    "\n",
    "# ====== End of solution ====="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de datos\n",
    "Antes de resolver cualquier problema es necesario entenderlo, para los problemas de aprendizaje máquina una de las herramientas mas importantes para comprender mejor a que nos enfrentamos es el visualizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "# Pintaremos los que tienen etiqueta 0 y etiqueta 1 de distinto color\n",
    "# Muestra un máximo de dp_to_plot puntos para cada clase\n",
    "dp_to_plot = 100\n",
    "\n",
    "# Grafica los datos malignos\n",
    "malignant_entries = data_train[malignant_idcs]\n",
    "ax.scatter(\n",
    "    # TODO: Ingresa los datos a graficar\n",
    "    # ====== Start of solution =====\n",
    "    x=...,\n",
    "    y=...,\n",
    "    # ====== End of solution =====\n",
    "    s=100,\n",
    "    color=\"r\", \n",
    "    marker=\"x\",\n",
    "    label=\"maligno\"\n",
    ")\n",
    "\n",
    "# Grafica los datos benignos\n",
    "benign_entries = data_train[benign_idcs]\n",
    "ax.scatter(\n",
    "    # TODO: Ingresa los datos a graficar\n",
    "    # ====== Start of solution =====\n",
    "\n",
    "    # ====== End of solution =====\n",
    "    s=100,\n",
    "    color=\"b\", \n",
    "    edgecolor='black',\n",
    "    marker=\"o\",\n",
    "    label=\"benigno\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La función sigmoide\n",
    "Podemos aplicar un modelo de regresión logística para encontrar el límite de separación que nos permita clasificar nuevos tumores, a partir de los datos de entrenamiento.Recordamos la función logística vista en clase:\n",
    "\n",
    "$ h_w(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "En la siguiente celda, visualiza la función logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    # TODO: Calcula la hipótesis h(z)\n",
    "    # ====== Start of solution =====\n",
    "    h = ...\n",
    "    # ====== End of solution =====\n",
    "    return h\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = logistic(x)\n",
    "# TODO: Grafica la función logística\n",
    "# ====== Start of solution =====\n",
    "\n",
    "# ====== End of solution ====="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos aprender un modelo de regresión logística, debemos encontrar los parámetros w que minimizen la función de pérdida. En regresión logística, el modelo de decisión consiste en:\n",
    "\n",
    "$ h_w(X) = \\frac{1}{1 + e^{-Xw}}$\n",
    "\n",
    "Donde:\n",
    "- $X$ corresponde a los datos proporcionados\n",
    "- $h_w(X)$ es la predicción o hipótesis de nuestro modelo de regresión logística\n",
    "\n",
    "Recuerda que para realizar las operaciones de manera correcta $X$ debe estar en su notación aumentada, es decir, tiene un uno adicional por cada datapoint para que se pueda añadir el sesgo: $X \\in \\mathbb{R}^ {D+1 \\times N }$. Por lo tanto, los pesos tienen este parámetro adicional también $ w \\in R^{D+1} $\n",
    "\n",
    "En este problema $D = 2$ ya que estamos utilizando el perímetro y la textura del tumor para hacer la predición.\n",
    "\n",
    "TODO: En la siguiente celda, calcula las predicciones de regresión logística para una inicialización aleatoria de los pesos $w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando W\n",
    "w = np.random.uniform(low=-1, high=1, size=(3,))\n",
    "\n",
    "# TODO: Genera el dataset de entrenamiento aumentado\n",
    "# para el conjunto de datos de entrenamiento data_train\n",
    "# aug_data_train = ?\n",
    "# ====== Start of solution =====\n",
    "aug_data_train = ...\n",
    "# ====== End of solution =====\n",
    "\n",
    "# TODO: Calcula el valor de z/ la combinación lineal de los pesos y datos de entrenamiento\n",
    "# ====== Start of solution =====\n",
    "z = ...\n",
    "# ====== End of solution =====\n",
    "pred = logistic(z)\n",
    "\n",
    "print(aug_data_train.shape)\n",
    "print(pred.shape)\n",
    "\n",
    "# Graficamos los puntos para visualizar la predicción de nuestro modelo actualmente\n",
    "plt.scatter(aug_data_train[:, 1],aug_data_train[:, 2], c=pred, cmap=\"RdYlGn\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida\n",
    "Como vemos, al inicializarse los pesos, el modelo clasifica la mayoría de los puntos como benignos(0), sin embargo una vez optimizada la función, el modelo aprende el valor de los pesos óptimos dados los datos de entrenamiento. Para optimizar los pesos necesitamos aplicar descenso de gradiente usando la función de pérdida.\n",
    "\n",
    "En clase vimos que la función de pérdida que se utiliza para problemas de clasificación binaria, se conoce como binary cross entropy loss (BCE)\n",
    "\n",
    "$ L(h_w(x), y) = - y \\log(h_w(x)) - (1 - y)\\log(1 - h_w(x)) $\n",
    "\n",
    "La funcion de logaritmo $\\log{x}$ tiende al infinito cuando $x=0$. Para evitar esto, es común agregar un valor muy pequeño $\\epsilon$ al valor dentro del logaritmo.\n",
    "\n",
    "$ L(h_w(x), y) = - y \\log(h_w(x) + \\epsilon) - (1 - y)\\log(1 - h_w(x) + \\epsilon) $\n",
    "\n",
    "Termina el método para calcular la función de pérdida correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(X, w, y):\n",
    "    \"\"\"\n",
    "        X: datos en notación aumentada,\n",
    "        w: pesos del modelo\n",
    "        y: etiquetas de los datos\n",
    "    \"\"\"\n",
    "    eps = 1e-5 \n",
    "    # TODO: Calcula la función de pérdida\n",
    "    # Nota - suma la variable eps dentro del logaritmo \n",
    "    # para evitar errores por números muy cercanos a log de 0\n",
    "    # ====== Start of solution =====\n",
    "    loss = ...\n",
    "    # ====== End of solution ======\n",
    "    return loss.mean(axis=0)\n",
    "\n",
    "loss = bce_loss(aug_data_train, w, target_train)\n",
    "print(\"Costo: %.3f\" %loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optmización\n",
    "Podemos resolver el problema anterior utilizando descenso por gradiente. Para ello, requeriríamos sacar el gradiente de la función de pérdida con respecto a los pesos e iterar como en el ejercicio de regresión lineal. Es decir, necesitaríamos el gradiente del BCE loss, por lo tanto no podemos usar la función anteriormente calculada ya que utilizamos un loss diferente (MSE).\n",
    "\n",
    "En esta ocasión resolveremos el problema con la librería de scikit-learn. Completa donde se indique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# TODO: Haz fit al modelo de regresión logística\n",
    "# usando los datos de entrenamiento\n",
    "# (data_train, target_train)\n",
    "# ====== Start of solution =====\n",
    "\n",
    "# ====== End of solution =====\n",
    "\n",
    "# TODO: Calcula las preddiciones\n",
    "# ====== Start of solution =====\n",
    "prediction = ...\n",
    "# ====== End of solution =====\n",
    "\n",
    "# TODO: Calcula la exactitud de tu predicción\n",
    "# en el set de entrenamiento (data_train, target_train)\n",
    "# Es decir, el promedio de datos correctamente clasificados\n",
    "# ====== Start of solution =====\n",
    "train_accuracy = ...\n",
    "# ====== End of solution =====\n",
    "\n",
    "# TODO: Calcula la probabilidad de que un tumor sea benigno\n",
    "# en el set de evaluación (data_test, target_test)\n",
    "# La dimensionalidad de prob debe ser (test_dp, )\n",
    "# Tip: Investiga la función \"LogisticRegression.predict_proba\"\n",
    "# ====== Start of solution =====\n",
    "prob = ...\n",
    "# ====== End of solution =====\n",
    "\n",
    "# TODO: Calcula la exactitud de tu predicción\n",
    "# en el set de evaluación (data_test, target_test)\n",
    "# Tip: Investiga la función \"LogisticRegression.score\"\n",
    "# ====== Start of solution =====\n",
    "test_accuracy = ...\n",
    "\n",
    "# ====== End of solution =====\n",
    "print(test_accuracy)\n",
    "\n",
    "# Graficamos los puntos para visualizar la predicción de nuestro modelo\n",
    "plt.scatter(data_test[:, 0],data_test[:, 1], c=prob, cmap=\"RdYlGn\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior, calculamos una predicción para cada punto de evaluación. Específicamente, el color de cada punto indica una probabilidad de que el tumor correspondiente sea benigno. \n",
    "<b>TODO: Contesta las siguientes preguntas</b> \n",
    "- ¿Por qué es útil predecir la probabilidad de que el tumor sea benigno en lugar de decir con certeza qué tipo de tumor es? \n",
    "- Intuitivamente ¿Qué necesitarías para tener una predicción más acertada?\n",
    "- Menciona otro problema real que se pueda resolver con un modelo de clasificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a28d4ef974f98ec68cd1ec8d370fdb002e6acfd68d2dd44e60697d887626ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
